{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-21T17:02:12.851720Z",
     "start_time": "2025-08-21T17:02:12.846826Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "from langchain_community.document_loaders import ArxivLoader"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T17:03:17.027278Z",
     "start_time": "2025-08-21T17:02:23.426459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = \"summarization\"\n",
    "model = \"sshleifer/distilbart-cnn-12-6\"\n",
    "summarizer = pipeline(task=task, model=model)"
   ],
   "id": "cae39595601b5761",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T17:04:01.617147Z",
     "start_time": "2025-08-21T17:03:33.749936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"prompt engineering\"\n",
    "loader = ArxivLoader(query=query, load_max_docs=1)\n",
    "docs = loader.load()"
   ],
   "id": "356aad45ef7d5fdb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T17:04:19.133669Z",
     "start_time": "2025-08-21T17:04:18.537929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% Data Preparation\n",
    "article_text = docs[0].page_content\n",
    "print(article_text)\n",
    "print(\"-------------\")"
   ],
   "id": "2ff402df7f9615cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompting AI Art: An Investigation into the Creative Skill of\n",
      "Prompt Engineering\n",
      "Jonas Oppenlaender1, Rhema Linder2, and Johanna Silvennoinen3\n",
      "1Independent Researcher, oppenlaenderj@acm.org\n",
      "2University of Tennessee, Knoxville, rlinder@utk.edu\n",
      "3University of Jyv¨askyl¨a, johanna.silvennoinen@jyu.fi\n",
      "Abstract\n",
      "We are witnessing a novel era of creativity where anyone can create digital content via prompt-based\n",
      "learning (known as prompt engineering). This paper investigates prompt engineering as a novel creative\n",
      "skill for creating AI art with text-to-image generation. In three consecutive studies, we explore whether\n",
      "crowdsourced participants can 1) discern prompt quality, 2) write prompts, and 3) refine prompts. We\n",
      "find that participants could evaluate prompt quality and crafted descriptive prompts, but they lacked\n",
      "style-specific vocabulary necessary for effective prompting.\n",
      "This is in line with our hypothesis that\n",
      "prompt engineering is a new type of skill that is non-intuitive and must first be acquired (e.g., through\n",
      "means of practice and learning) before it can be used. Our studies deepen our understanding of prompt\n",
      "engineering and chart future research directions. We conclude by envisioning four potential futures for\n",
      "prompt engineering.\n",
      "1\n",
      "Introduction\n",
      "We are entering an era in which anybody can generate digital images from text — a democratization of\n",
      "art and creative production. In this novel creative era, humans work within a human-computer co-creative\n",
      "framework (Kantosalo, Thattai Ravikumar, Grace, & Takala, 2020).\n",
      "Emerging digital technologies will\n",
      "co-evolve with humans in this digital revolution, which requires the renewal of human capabilities and\n",
      "competences (Haddington et al., 2021; H. Onan Demirel & Sha, 2024) and a human-centered design process\n",
      "(Grassini & Koivisto, 2024).\n",
      "One increasingly important human skill in this context is prompting due\n",
      "to it providing an intuitive language-based interface to artificial intelligence (AI). Prompting (or “prompt\n",
      "engineering”) is the skill and practice of writing inputs (“prompts”) for generative models (Liu & Chilton,\n",
      "2022; Oppenlaender, 2022). Prompt engineering is iterative and interactive — a dialogue between humans\n",
      "1\n",
      "arXiv:2303.13534v3  [cs.HC]  4 Jul 2024\n",
      "and AI in an act of co-creation. As generative models become more widespread, prompt engineering has\n",
      "become an important research area on how humans interact with AI (Bach et al., 2022; Dang, Goller,\n",
      "Lehmann, & Buschek, 2023; Dang, Mecke, Lehmann, Goller, & Buschek, 2022; Deckers et al., 2023; Hou,\n",
      "Dong, Wang, Li, & Che, 2022; Jeong Soo Kim & Baek, 2024; Jiang et al., 2022; Liu & Chilton, 2022;\n",
      "Oppenlaender, Silvennoinen, Paananen, & Visuri, 2023; Reynolds & McDonell, 2021).\n",
      "One area where prompt engineering has been particularly useful is the field of digital visual art. Image\n",
      "generation is often utilised in the later stage of the creation process in generating solutions, not in the\n",
      "ideation phase (Lee, Law, & Hoffman, 2024). State-of-the-art image generation systems, such as OpenAI’s\n",
      "DALL-E (Ramesh, Dhariwal, Nichol, Chu, & Chen, 2022), Midjourney (Midjourney, 2022), and Stable\n",
      "Diffusion (Rombach, Blattmann, Lorenz, Esser, & Ommer, 2022), have been trained on large collections of\n",
      "text and images collected from the World Wide Web. These systems can synthesize high-quality images in a\n",
      "wide range of artistic styles from textual input prompts (Gabha, 2022; Liu & Chilton, 2022; Oppenlaender,\n",
      "2022, 2023). Practitioners of text-to-image generation often use prompt engineering to improve the quality\n",
      "of their digital artworks (Liu & Chilton, 2022). Within the community of practitioners, certain keywords\n",
      "and phrases have been identified that act as “prompt modifiers” (Oppenlaender, 2023). These keywords\n",
      "can, if included in a prompt, improve the quality of the generative model’s output or make images appear\n",
      "in a specific artistic style (Gabha, 2022; Liu & Chilton, 2022; Oppenlaender, 2022). While a short prompt\n",
      "may already produce impressive results with these generative systems, the use of prompt modifiers can help\n",
      "practitioners unlock the systems’ full potential (Oppenlaender, 2022, 2023; Xie, Pan, Ma, Jie, & Mei, 2023).\n",
      "The skillful application of prompt modifiers can distinguish expert practitioners of text-to-image generation\n",
      "from novices.\n",
      "However, how people interact with image-generation systems is a relatively unexplored phenomenon\n",
      "(Kim, Eun, Oh, & Lee, 2024). In addition, whether prompt engineering is an intuitive skill or whether\n",
      "this skill must be acquired (e.g., through means of practice and iterative learning) has, so far, not been\n",
      "investigated. Investigating the skill of prompt engineering is important for several reasons.\n",
      "For the field of AI art it is important to inform the development of future image generation systems and\n",
      "interfaces. A look at Stable Diffusion’s Discord channel1 provides anecdotal evidence that some prompts\n",
      "and keywords combinations circulating in the community of practitioners are not intuitive. Such keywords\n",
      "include, for instance, the modifier “by Greg Rutkowski” or other popular keywords, such as “smooth,”\n",
      "“elegant,” “luxury,” “octane render,” “trending on,” and “artstation”. These keywords are often used in\n",
      "combination with each other to boost the quality of generated images (Oppenlaender, 2023), resulting in\n",
      "unintuitive keyword combinations that a human user would likely never have chosen to describe the image\n",
      "to another human. With these many keywords comes a loss of control over the outcome. There is a high\n",
      "randomness to the outcome of text-to-image generation, and controlling the image generation (without\n",
      "resorting to additional tools, such as ControlNet (Zhang, Rao, & Agrawala, 2023), is difficult, even for\n",
      "1https://discord.com/channels/1002292111942635562/\n",
      "2\n",
      "experts in prompt engineering). Keywords and modifiers are commonly applied by practitioners in the AI\n",
      "art community, but may confront laypeople with challenges of understanding the effect of modifiers on the\n",
      "resulting image. Further confounding the problem is that keywords in prompts can affect both the subject\n",
      "and style of a generated image simultaneously.\n",
      "For the field of education, investigating the skill of prompt engineering is important, since the popularity\n",
      "and importance of the practice of prompt engineering is growing.\n",
      "Prompt engineering has been proven\n",
      "effective in solving difficult problems that were previously too complex to solve.\n",
      "This property makes\n",
      "prompt engineering useful in industry contexts. Therefore, a legitimate question to ask if whether prompt\n",
      "engineering should be included as a subject in school and higher education curricula. To inform this decision,\n",
      "one needs to know more about prompt engineering as a skill – what is its learning curve, how many hours\n",
      "would it take to learn, or is it even a skill? If people can just simply apply this language-based skill without\n",
      "much learning is important information to have in this context.\n",
      "Furthermore, whether prompt engineering is a skill that humans apply intuitively or whether it is a new\n",
      "type of skill that needs to be acquired is important not only for the field of AI art and education, but\n",
      "also for research on human-AI interaction and the future of work in general. Consider, for instance, the\n",
      "sector of (higher) education and its future curricula. Agents based on language models (LMs) based have\n",
      "become vastly popular and promise to solve complex problems that previously required software engineering\n",
      "expertise (Wu et al., 2024). Such LM-based agents heavily rely on prompt engineering. The question, then,\n",
      "is whether current educational curricula should be extended with teaching on prompt engineering. However,\n",
      "if prompt engineering was a skill that everyone with sufficient knowledge of the English language could just\n",
      "apply without having to learn this skill, it would mean that extending the curricula with prompt engineering\n",
      "would not be necessary. An extension would take away from the time to teach other, more important, skills.\n",
      "On the other hand, if there is a learning curve to it, or if the skill proves to be transferable enough to be\n",
      "valuable, then its adoption in curricula would be warranted.\n",
      "A source for unintuitiveness of the current practice of prompt engineering is a potential misalignment\n",
      "between the human-written prompts and the way in which text-to-image models interpret prompts. Com-\n",
      "pared to how we humans understand a prompt and its constituents, text-to-image generative models may\n",
      "attach very different meanings to some keywords in the prompt. Further, many AI-generated images are\n",
      "shared on social media, often with stunning results. However, if what we see on social media is the result of\n",
      "the application of prompt engineering by skilled experts, then the generative content that we encounter on\n",
      "social media could be skewed by a small group of highly skilled practitioners. Or from another perspective,\n",
      "if prompt engineering is an acquired skill that requires expertise and training, this could give rise to novel\n",
      "creative professions with implications for the future of work. On the other hand, we run the risk of assigning\n",
      "too much importance to prompting as a method for interacting with generative models if prompt engineering\n",
      "is an innate ability and an intuitive artistic skill that is acquired quickly (Oppenlaender, Silvennoinen, et\n",
      "al., 2023; Oppenlaender, Visuri, Paananen, Linder, & Silvennoinen, 2023).\n",
      "3\n",
      "In this paper, we explore the creative skill of prompt engineering in three studies with a total of 227 par-\n",
      "ticipants recruited from Amazon Mechanical Turk (MTurk), a crowdsourcing platform. The timing of our\n",
      "three studies is significant (see Table 1. The studies were conducted at a time when text-to-image generation\n",
      "was still relatively unknown. This allowed us to study whether participants could apply prompt engineering\n",
      "intuitively, or whether prompt engineering is a skill that must be learned through many iterations. We\n",
      "expand on the timing of this study in Section 6.3.\n",
      "Table 1: Overview of the three studies presented in this paper.\n",
      "No.\n",
      "Participants\n",
      "Study\n",
      "date\n",
      "Study purpose\n",
      "Research question\n",
      "1\n",
      "52\n",
      "May 19–23, 2022\n",
      "Test participants’ understanding\n",
      "of prompt quality\n",
      "Are participants able to tell the\n",
      "quality of an image from the tex-\n",
      "tual input prompt?\n",
      "2\n",
      "125\n",
      "June 12–23, 2022\n",
      "Test participants’ ability to write\n",
      "prompts\n",
      "Can participants effectively write\n",
      "prompts to create digital art-\n",
      "works?\n",
      "3\n",
      "50\n",
      "June 20–27, 2022\n",
      "Test participants’ ability to revise\n",
      "their own prompts\n",
      "Can participants improve their\n",
      "prompts to generate better digi-\n",
      "tal artworks?\n",
      "In Study 1, we explore participants’ understanding of how a text-to-image generation system produces\n",
      "images of varying quality depending on the phrasing of input prompts. A feeling of what contributes to\n",
      "the quality of a prompt could enable participants to write prompts and create high-quality images.\n",
      "In\n",
      "our within-subject experiment, participants separately rated the aesthetic appeal of textual prompts and\n",
      "matching images generated with a text-to-image generation system. We hypothesize that a high degree of\n",
      "consistency within the participants’ two ratings may point toward there being a strong understanding of\n",
      "what makes a “good” prompt.\n",
      "Key insights from Study 1: We find participants are able to grasp what makes a “good” prompt.\n",
      "Being able to discern good from bad prompts would, in theory, allow participants to write effective prompts.\n",
      "In Study 2, we test the insights from the above two studies in practice.\n",
      "We invite participants to\n",
      "apply their knowledge and expertise by writing three input prompts for a text-to-image generation system\n",
      "with the specific aim of creating a digital artwork (and without seeing the generated images). We analyze\n",
      "participants’ use of descriptive language and the use of prompt modifiers that could influence the quality\n",
      "and style of the resulting artworks. In Study 3, we then invite the same participants who participated in\n",
      "the Study 2 to review the images generated from their own prompts. Each participant was asked to improve\n",
      "their prompts with the specific task of creating an artwork of high visual quality. Our hypothesis is that if\n",
      "prompt engineering is an intuitive skill innate to humans, participants will be able to apply it immediately.\n",
      "On the other hand, if participants are not able to significantly improve their images due to few interactions\n",
      "with the text-to-image generation system within our studies, then this may indicate that the skill of prompt\n",
      "engineering needs to be acquired before it can be applied in practice.\n",
      "4\n",
      "Key insights from studies 2 and 3: We find that while participants were able to describe artworks in\n",
      "rich descriptive language, almost none of the participants used specific keywords to adapt the style of their\n",
      "artworks or modify the images in other ways. Moreover, participants were not able to significantly improve\n",
      "the quality of the artworks in the follow-up study. This points to prompt engineering being a non-intuitive\n",
      "skill that people first need to acquire before it can be applied in meaningful ways.\n",
      "In summary, our three studies find that while laypeople participants had the prerequisites to write prompts\n",
      "for AI art and were good at crafting descriptive prompts, they lacked style-specific vocabulary necessary for\n",
      "effective prompt engineering. We conclude by speculating on four potential futures for prompt engineering.\n",
      "2\n",
      "Related Work\n",
      "2.1\n",
      "Text-to-Image Generation with Deep Learning\n",
      "Text-to-image generation is a type of generative deep learning technology that allows users to create images\n",
      "from text descriptions.\n",
      "This technology has gained significant interest since early 2021, when OpenAI\n",
      "published the results of DALL-E (Ramesh et al., 2021) and the weights of their CLIP model (Radford et al.,\n",
      "2021). CLIP is a multi-modal model trained on over 400 million text and image pairs from the Web. The\n",
      "model can be used in text-to-image generation systems to guide the generation of high-fidelity images. Many\n",
      "approaches and architectures for image generation with deep learning have since been developed, such as\n",
      "diffusion models (Dhariwal & Nichol, 2021). These approaches typically use machine learning models trained\n",
      "with contrastive language-image techniques using training data scraped from the Web. These systems are\n",
      "text-conditional, meaning they use text as input for image synthesis.\n",
      "This input, known as “prompt,”\n",
      "describes the image to the system, which then generates one or more images without further input.\n",
      "2.2\n",
      "Prompt Engineering for AI Art\n",
      "The practice of crafting input prompts is referred to as prompt engineering (or prompting for short). In this\n",
      "section, we explain the ‘engineering’ character of prompt engineering and how prompt engineering is applied\n",
      "for generating AI art.\n",
      "2.2.1\n",
      "The engineering character of prompting\n",
      "The term prompt engineering was originally coined by Gwern Branwen in the context of writing textual\n",
      "inputs for OpenAI’s GPT-3 language model (Liu & Chilton, 2022). ‘Engineering,’ in this case, does not\n",
      "refer to a hard science as found in science, technology, engineering, and mathematics (STEM) disciplines.\n",
      "Prompt engineering is a term that originates from within the online community of practitioners. Practitioners\n",
      "include artists and creative professionals, but also novices, amateurs, and more serious “Pro-Ams” (Hoare,\n",
      "Benford, Jones, & Milic-Frayling, 2014) aiming, for instance, to sell their creations as digital art based on\n",
      "5\n",
      "non-fungible tokens (NFTs) (Kugler, 2021). Not every member of this online community may identify as a\n",
      "prompt engineer. An alternative self-understanding could be “promptist” (Hayward, 2022) or “AI artist”\n",
      "(Zylinska, 2020). One aspect of prompt engineering that relates to its engineering character is that it often\n",
      "involves systematic experimentation through trial and error (Liu & Chilton, 2022). The challenge for the\n",
      "prompt engineer is not only to find the right terms to describe an intended output and the right m, but also\n",
      "to anticipate how other people would have described and reacted to the output on the World Wide Web.\n",
      "2.2.2\n",
      "Prompt engineering for creating AI art\n",
      "Art generated by artificial intelligence, or “AI art” (Zylinska, 2020), has become a popular application for\n",
      "prompt engineering (Oppenlaender, 2022). An online community around AI art has formed, sharing images\n",
      "and prompts on various platforms.\n",
      "Within this community, certain practices for writing prompts have\n",
      "emerged. For example, prompts often follow a specific pattern, such as the following template (Smith, 2022):\n",
      "[Medium] [Subject] [Artist(s)] [Details] [Image repository support]\n",
      "A typical prompt could be (Allen, 2022):\n",
      "A beautiful painting of a singular lighthouse, shining its light across a tumultuous sea of blood\n",
      "by greg rutkowski and thomas kinkade, trending on artstation.\n",
      "Prompt modifiers, such as the underlined terms above, are added to a prompt to influence the resulting\n",
      "image in a specific way (Liu & Chilton, 2022; Oppenlaender, 2022, 2023). Prompt modifiers are an important\n",
      "technique in prompt engineering for AI art because they allow the prompt engineer to control the output\n",
      "of the text-to-image generation system. Prompt modifiers may make the resulting images subjectively more\n",
      "aesthetic and attractive (Liu & Chilton, 2022; Oppenlaender, 2022).\n",
      "Different types of prompt modifiers are used in the AI art community (Oppenlaender, 2023), but the two\n",
      "most common types of modifiers affect the style and quality of images. These prompt modifiers consist of\n",
      "specific keywords and phrases that have been found to modify the style or quality of an image (or both).\n",
      "Modifiers that affect the quality of images can be referred to as ‘quality boosters’ (Oppenlaender, 2023), and\n",
      "include phrases such as “trending on artstation,” “unreal engine,” “CGSociety,” “8k,” and “postprocessing.”\n",
      "Style modifiers affect the style of an image and can include a wide variety of open domain keywords and\n",
      "phrases, such as “oil painting,” “in the style of surrealism,” or “by James Gurney” (Oppenlaender, 2023).\n",
      "Human-centered research on prompt engineering for text-to-image synthesis in the field of Human-\n",
      "Computer Interaction (HCI) is still in its early stages. The study by Liu and Chilton (2022) on subject\n",
      "and style keywords in textual input prompts mentioned that without knowledge of prompt modifiers, users\n",
      "must engage in “brute-force trial and error”. The authors presented design guidelines to help people produce\n",
      "better results with text-to-image generative models (Liu & Chilton, 2022). Qiao, Liu, and Chilton (2022)\n",
      "conducted an experiment on using images as visual input prompts, resulting in design guidelines for im-\n",
      "proving subject representations in AI art. Besides these guidelines, there are also many community-created\n",
      "6\n",
      "resources that offer guidance for novices and practitioners of AI art, such as the “Traveler’s Guide to the\n",
      "Latent Space” by Smith (2022), Zippy’s “Disco Diffusion Cheatsheet” (Allen, 2022), and the “Disco Diffusion\n",
      "Artist Studies” by Gabha (2022). These resources provide a wealth of information about prompt modifiers\n",
      "for producing high-quality visual artifacts.\n",
      "2.3\n",
      "Prompt Engineering as a Skill\n",
      "Merriam-Webster defines ‘skill’ as “the ability to use one’s knowledge effectively and readily in execution\n",
      "or performance” and “a learned power of doing something competently: a developed aptitude or ability”\n",
      "(Merriam-Webster, 2024). This definition captures the essence of skill as not only having knowledge, but\n",
      "also the capability to apply the knowledge effectively in practical situations and in real-world contexts.\n",
      "In our work, we define ‘skill in prompt engineering’ as the ability to effectively utilize language and prior\n",
      "knowledge to craft prompts that guide generative models towards desired outputs. This encompasses not\n",
      "only the basic knowledge of the relevant language syntax but also the strategic use of prompt modifiers —\n",
      "elements that refine or alter the direction of generative outputs. Our study aims to investigate whether\n",
      "individuals, particularly participants recruited from a crowdsourcing platform, possess the necessary founda-\n",
      "tional knowledge to write effective prompts. More importantly, we assess if these participants can translate\n",
      "this knowledge into practical application, demonstrating a skilled use of prompt modifiers in the context of\n",
      "text-to-image generation for AI art. The inability to effectively apply knowledge in practice may suggest a\n",
      "lack of skill, underscoring the need for knowledge acquisition and refinement through learning and training.\n",
      "This approach aligns with our objective to elucidate whether prompt engineering is an innate ability or\n",
      "whether it must be acquired (e.g., through practice and learning).\n",
      "2.4\n",
      "Prior Work on Applying Skill in Practice\n",
      "Our research is related to prior work focusing on how individuals acquire skills and how they apply them in\n",
      "practice. In particular, learning how to use web search is a related area of work. This section is structured\n",
      "around three main themes identified in the literature: the divergence between search and domain expertise,\n",
      "the strategies involved in how people rewrite a query after a failed attempt, and teaching how to improve\n",
      "query authorship.\n",
      "Divergence Between Search and Domain Expertise\n",
      "The first theme addresses the relationship between domain expertise and search expertise. White, Dumais,\n",
      "and Teevan (2009) provide an insightful analysis of how domain knowledge influences web search behav-\n",
      "ior. Their work demonstrates that domain experts and novices exhibit markedly different search strategies\n",
      "and outcomes. This finding is supported and extended by Wood et al. (2016), who explore the relative\n",
      "contributions of domain knowledge and search expertise in conducting effective internet searches (Huang &\n",
      "7\n",
      "Efthimiadis, 2009). These studies underscore the distinct nature of search expertise, separate from domain-\n",
      "specific knowledge, highlighting its importance in effective information retrieval.\n",
      "Query Reformulation Strategies\n",
      "The second theme revolves around how individuals modify their search queries following unsuccessful at-\n",
      "tempts. Huang and Efthimiadis (2009) offer a comprehensive examination of query reformulation strategies\n",
      "in web search logs. Their analysis reveals the common patterns and tactics users employ when their initial\n",
      "search queries fail to yield desired results. This research is crucial in understanding the adaptive behaviors\n",
      "of users in response to the challenges they encounter during web searches.\n",
      "Educational Approaches to Query Authorship\n",
      "The third theme relates to methods for teaching effective query formulation. Bateman, Teevan, and White\n",
      "(2012) contribute significantly to this area through their development of the Search Dashboard tool. Their\n",
      "study examines how tools that facilitate reflection and comparison can impact users’ search behaviors, leading\n",
      "to more effective search strategies. This work is particularly relevant for designing educational interventions\n",
      "and tools aimed at enhancing the search skills of users.\n",
      "Our studies draw upon and contribute to these existing bodies of work. We extend the understanding\n",
      "of how individuals apply their knowledge in writing prompts, and how they reformulate a prompt in an\n",
      "attempt to improve upon a first prompt. Both are crucial aspects of information literacy in the digital age.\n",
      "3\n",
      "Study 1: Understanding Prompt Engineering\n",
      "We conducted a within-subject experiment to study participants’ understanding of prompt engineering. Par-\n",
      "ticipants were asked to rate the textual prompts and the corresponding AI-generated images. We hypothesize\n",
      "that participants with a strong understanding of prompt engineering would exhibit a high consistency be-\n",
      "tween the ratings in the two modalities. In other words, if someone can predict the aesthetic appeal of an\n",
      "image from its textual prompt, they likely have a good sense of how prompt engineering works. The study\n",
      "design reflects the knowledge that prompt engineers would draw on in practice: first write a prompt with the\n",
      "intention to produce a high quality image, then observe and assess the quality of the resulting image. A good\n",
      "understanding of textual prompts is crucial for predicting how well a prompt will perform. For instance,\n",
      "prompts incorporating rich descriptive language and multiple prompt modifiers tend to yield artworks of\n",
      "higher quality compared to prompts lacking these attributes.2\n",
      "In the following section, we describe the\n",
      "study design in detail.\n",
      "2Note that some state-of-the-art image generation systems, like Midjourney, are “greedy” and will try to turn any input\n",
      "into an aesthetic artwork, even if the prompt is short or non-descriptive. See Section 6.4 for more on this issue.\n",
      "8\n",
      "3.1\n",
      "Method\n",
      "3.1.1\n",
      "Research materials\n",
      "We curated a set of prompts and images created with Midjourney, a text-to-image generation system and\n",
      "community of AI art practitioners. Using purposeful sampling, we selected 111 images from the corpus of\n",
      "thousands of Midjourney images generated by the first author. Our choice to use the author’s image corpus\n",
      "has several advantages. The corpus includes images with a range of different prompt modifiers commonly\n",
      "used on Midjourney and we avoid intruding on others’ intellectual property rights. Further, the author has\n",
      "experience with text-to-image generation and can distinguish failed attempts from successful ones. This\n",
      "allowed us to purposefully sample images with varying levels of subjective quality. Specifically, we selected\n",
      "59 images judged as failed attempts and 52 images of high aesthetic quality. We kept the format of four\n",
      "images per prompt, as it resembles the output a prompt engineer would typically receive on Midjourney.\n",
      "To assess the aesthetic quality of the 111 images in the dataset, we recruited ten volunteer raters from\n",
      "two academic institutions. The raters had diverse backgrounds in Computer Science, Information Sciences,\n",
      "Human-Computer Interaction, Cognitive Science, Electrical Engineering, and Design. They consisted of 2\n",
      "Professors, 3 PostDocs, 3 PhD students, 1 Master student, and 1 project engineer (5 men and 5 women,\n",
      "age range 24–48 years). Raters completed a simple binary classification task to classify the images as high\n",
      "or low quality based on their aesthetic appeal. Raters were informed that there was an unequal number of\n",
      "images in each category. The inter-rater agreement over all images, as measured by Fleiss’ kappa, was fair,\n",
      "κ = 0.34, z = 23.9, p < 0.00, 95% CI [0.31, 0.37].We discussed the ratings and selected images for further\n",
      "study. Only images with perfect agreement among the ten raters were selected for further study. From the\n",
      "set with perfect agreement among raters, we selected ten high- and ten low-quality images.\n",
      "We contend that high-quality images can be determined by aesthetic quality ratings from 10 volunteers,\n",
      "without disclosing the prompts to them, for the following reasons. Classifying images with high and low\n",
      "aesthetics is a relatively easy task (Kong, Shen, Lin, Mech, & Fowlkes, 2016). The evaluation of ‘high-quality’\n",
      "and ‘low-quality’ images by a limited number of volunteers is not aimed at establishing a universal standard\n",
      "of image quality. We contend that understanding the subjective quality perception of AI-generated images is\n",
      "as important as their fidelity to the prompts. While we recognize the importance of the alignment between\n",
      "the image and its corresponding prompt in determining quality, our primary focus in this study is on the\n",
      "aesthetic appeal as perceived by individuals without the context of the prompts. Inspired by the “wisdom\n",
      "of the crowd” (Surowiecki, 2005), our objective is to leverage perceptual differences in aesthetic appreciation\n",
      "among multiple individuals in order to devise two distinct sets of images, without the influence of the original\n",
      "prompts used to create the images. Future studies could integrate prompt fidelity as an additional dimension\n",
      "of image quality.\n",
      "The final set contains 20 images and respective prompts of varying quality (see Figure 1 and Appendix A).\n",
      "9\n",
      "1a) High aesthetic appeal\n",
      "1b) Low aesthetic appeal\n",
      "Figure 1: Exemplars of images used in Study 2. The full set of images and prompts is listed in Appendix A.\n",
      "3.1.2\n",
      "Study design\n",
      "We conducted a within-subject experiment with two distinct conditions. The first condition required par-\n",
      "ticipants to rate 20 AI-generated images on a 5-point Absolute Category Rating (ACR) scale (Pinson et al.,\n",
      "2012; Siahaan, Redi, & Hanjalic, 2014) (refer to Figure 2a). The ACR is an established scale for producing\n",
      "reliable judgments (Siahaan et al., 2014), noted for its insensitivity to variables such as lighting, monitor\n",
      "calibration, language, and country (Pinson et al., 2012). In the second condition, participants were presented\n",
      "with 20 textual prompts and asked to imagine and rate the images they believed these prompts would gen-\n",
      "erate, using the same ACR scale. Here, participants were shown only the prompts, not the actual images.\n",
      "Each prompt was introduced with “Imagine the image generated from the prompt: . . . ” accompanied by a\n",
      "descriptive task reminder (see Figure 2b).\n",
      "a)\n",
      "b)\n",
      "Figure 2: Example of items used in Study 1 for rating the aesthetic appeal of a) AI-generated artworks\n",
      "and b) prompts. The latter task was prefixed by an instruction to “imagine the image generated from the\n",
      "prompt.”\n",
      "The instructions were carefully designed to avoid confounding factors. For instance, we used neutral\n",
      "wording and avoided referring to the images as artworks to prevent higher positive aesthetic ratings (Arai\n",
      "& Kawabata, 2016; Gerger, Leder, & Kremer, 2014; Pelowski, Gerger, Chetouani, Markey, & Leder, 2017;\n",
      "Van Dongen, Van Strien, & Dijkstra, 2016). Note that our aim was not to measure exact ground-truth ratings\n",
      "for aesthetic appeal, but to study differences in ratings within participants in a within-subject design.\n",
      "After the two conditions, we collected basic demographics including participants’ self-rated interest in\n",
      "art and experience with practicing art.\n",
      "We also included an optional open-ended item for participants\n",
      "10\n",
      "to elaborate on their experience with text-to-image generation.\n",
      "Experience with art and text-to-image\n",
      "generation were measured on 5-point Likert scales, and self-rated experience with art was measured as a\n",
      "binary variable.\n",
      "3.1.3\n",
      "Participant recruitment and procedure\n",
      "We recruited US-based participants from Amazon Mechanical Turk (MTurk) with a task approval rate\n",
      "greater than 95% and at least 1000 completed tasks. This combination of qualification criteria is common\n",
      "in crowdsourcing research (e.g., (Hope et al., 2022)). The experiment was implemented as a survey task and\n",
      "hosted on Google Forms. Participants were paid US$1.50 for completing the survey. The price was deter-\n",
      "mined from the average completion times in a small-scale pilot study (N = 9, US$1 per task) (Oppenlaender,\n",
      "Abbas, & Gadiraju, 2024).\n",
      "The task consisted of 31 items in total, including a consent form, an introduction to the study, 20 ratings\n",
      "of prompts, 20 ratings of images, ten demographic items, and one consistency check. Participants underwent\n",
      "the two conditions (rating of prompt and rating of images) in balanced order. Half of the participants first\n",
      "rated the prompts, then the images, and the other half vice versa.\n",
      "To prevent bias, we anonymized the filenames of the images and assigned a random numeric code to each\n",
      "image to make it harder to associate the images with the prompts from the previous survey section. As a\n",
      "check for consistency, we duplicated one image and collected a rating for this image (L1, see Appendix A.2).\n",
      "Participants who differed in their rating for this duplicated image by greater than one category on the ordinal\n",
      "ACR scale were excluded from analysis. We excluded four participants for failing this consistency check and\n",
      "another two participants for having completed the survey without completing the task on MTurk. The final\n",
      "sample included 52 participants.\n",
      "3.1.4\n",
      "Analysis\n",
      "We hypothesize that participants can detect a relationship between the quality of a prompt, in terms of its\n",
      "ability to depict visual art through human imagination, and the quality of the visual artwork generated by\n",
      "the text-to-image generation system. To test this hypothesis, we performed a correlation test using Pearson’s\n",
      "product-moment correlation to look at the relationship between paired scores for each type. We investigated\n",
      "the correlation between art experience and average error for each participant. Average error per participant\n",
      "was calculated by taking the average absolute difference between each pair of prompt and artwork rating.\n",
      "For example, if all prompts were rated as 2 and all artworks as 5, the average error would be 3.\n",
      "11\n",
      "3.2\n",
      "Results\n",
      "3.2.1\n",
      "Participants\n",
      "Participants (N = 52) were between 24 and 67 years of age (M = 38.2 years, SD = 12.98 years) and included\n",
      "31 men and 21 women (no non-binary) from diverse educational backgrounds (27 Bachelor’s degrees, 10 Mas-\n",
      "ter’s degrees, among others). A sizable fraction of the participants (46%) reported having an educational\n",
      "background in the arts. Twenty-nine participants agreed and nine strongly agreed that they had visited\n",
      "many museums and art galleries (M = 3.60, SD = 1.18). However, participants did not practice art often\n",
      "(M = 3.08, SD = 1.28). Overall, participants were interested in AI generated art (M = 3.69, SD = 0.83),\n",
      "but had little experience with text-to-image generation (M = 2.58, SD = 1.43). Only three participants\n",
      "mentioned having used text-to-image generation (DALL-E mini/Craiyon) before.\n",
      "3.2.2\n",
      "Visual and prompt ratings\n",
      "Our study design asked participants to rate both Prompts and Visual artwork. Since participants did not\n",
      "receive special training for prompt engineering or text-based AI art, our goal was to understand the quality\n",
      "of our participants’ perceptions. We show the histogram of scores broken into groups for each Art Type\n",
      "(Prompt and Artwork) in Figure 3 and Table 2 and the Quality (high or low) as described previously.\n",
      "Visually, these show differences across groups, with the distributions of Artworks leaning towards higher\n",
      "quality than prompts.\n",
      "We used a Kruskal-Wallis rank sum test on these four unique groups, finding a significant difference\n",
      "between the study conditions (χ2 = 231.4, p < 1015, df = 3). Following this significant result, we performed\n",
      "post-hoc Dunn’s test pairwise across each group with Bonferroni correction for p-values. Each of these pairs\n",
      "had significant results with a p-value of less than 10−4, except for Artwork–High versus Prompt–High, in\n",
      "which p < .004. This implies that the median values among all comparisons of groups (i.e. Artwork–High,\n",
      "Artwork–Low, Prompt–High, Prompt–Low) are significantly different from each other.\n",
      "Participants were able to differentiate images with low visual aesthetic quality from high quality images.\n",
      "Artwork–High has a higher mean rating (µ = 3.70) compared to Prompt–Low (µ = 3.39). Likewise, partici-\n",
      "pants were able to distinguish between high and low quality by imaging what would be produced based on\n",
      "textual prompts. Prompt–High has a higher mean rating (µ = 3.87) compared to Prompt–Low (µ = 2.78).\n",
      "The overall span between the Artwork High and Low is larger for Prompts (3.87 −2.78 = 1.09) than for\n",
      "Artworks (3.70 −3.39 = .31). Both High and Low quality Artworks had distributions that favored a rating\n",
      "of 4, while Prompt–Low has a relatively flat distribution across values of 1 to 4 (see Figure 3).\n",
      "3.2.3\n",
      "Connection between visual image and prompt quality\n",
      "While in theory, prompts that can help readers conjure (i.e. visualize or imagine) more aesthetically ap-\n",
      "pealing mental images will also generate better Artwork, it is not clear whether this would be the case for\n",
      "12\n",
      "Artwork\n",
      "Prompt\n",
      "High\n",
      "Low\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "Rating\n",
      "count\n",
      "Quality\n",
      "High\n",
      "Low\n",
      "Figure 3: Histograms of rating scores provided by participants in the two conditions of the within-subject\n",
      "study. Scores by participants (N = 52) for images (left) and prompts (right) with high aesthetic quality\n",
      "(top; H1–H10) and low aesthetic quality (bottom; L1–L10) in Study 2.\n",
      "Table 2: Average rating across Art Type and Quality in Study 1\n",
      ".\n",
      "Art Type\n",
      "Quality\n",
      "Mean\n",
      "Std Dev\n",
      "Artwork\n",
      "High\n",
      "3.70\n",
      "1.04\n",
      "Artwork\n",
      "Low\n",
      "3.39\n",
      "1.15\n",
      "Prompt\n",
      "High\n",
      "3.87\n",
      "1.07\n",
      "Prompt\n",
      "Low\n",
      "2.78\n",
      "1.28\n",
      "crowdsourced participants. While our participants were not able to directly associate Prompts to Artworks,\n",
      "each Artwork had a matching Prompt. We used a Person’s product-moment correlation test to measure\n",
      "whether ratings for the Prompt and Artwork are correlated. The test shows a weak (r = .29, 95% CI [.23,\n",
      ".34]) but significant (p < 10−15) positive correlation between ratings from Artworks and Prompts. This\n",
      "indicates that when a Prompt is seen as having a higher quality, that it is also more likely that the Artwork\n",
      "will appear as having a high quality.\n",
      "4\n",
      "Study 2: Writing Prompts\n",
      "Our aim with this study is to probe whether laypeople recruited from a crowdsourcing platform have the\n",
      "ability to come up with effective input prompts for text-to-image generation systems with a specific fo-\n",
      "cus on generating digital artworks. The presence of style modifiers in an input prompt may indicate an\n",
      "understanding of text-to-image generation and how effective prompts can be formulated.\n",
      "13\n",
      "4.1\n",
      "Method\n",
      "4.1.1\n",
      "Study design\n",
      "We designed a creative crowdsourcing task eliciting three textual prompts from each participant. The task\n",
      "included a short introduction and the following instructions:\n",
      "Imagine an artificial intelligence that turns textual input prompts into digital artworks. Your\n",
      "task is to produce three artworks. To this end, you will write three different input prompts for\n",
      "the artificial intelligence. You should aim to maximize the visual attractiveness and aesthetic\n",
      "qualities of the digital artworks generated from your input prompts.\n",
      "Participants were asked to make their artworks as visually attractive and high-quality as possible. We did\n",
      "not mention that prompt modifiers could be used in the prompt and wrote the instructions to avoid priming\n",
      "participants with a specific style (i.e., we told participants to produce ‘artworks’ rather than ‘paintings’).\n",
      "Note, however, that we did not aim to precisely measure attractiveness and quality, but wanted participants\n",
      "to think about the overall visual and aesthetic quality of the images. Participants were told that there\n",
      "was no right or wrong answer, but tasks would be rejected if they didn’t follow the instructions. To avoid\n",
      "influencing participants prompt modifications in our follow-up study (Study 3), we merely collected prompts\n",
      "from participants in this study — the outcome of the image generation was not shown to participants in this\n",
      "study.\n",
      "As additional questions in the task, we asked whether the participant had experience with text-to-image\n",
      "generation and we collected basic demographics. Participants were paid US$0.16 per completed task. The\n",
      "pricing was estimated from the average task completion times in a pilot study (N = 10, US$0.12 per task).\n",
      "In this pilot study, we noticed some participants wrote a series of consecutive instructions for the AI. The\n",
      "task design and instructions were subsequently adjusted to elicit complete prompts.\n",
      "4.1.2\n",
      "Participant recruitment\n",
      "We recruited 137 unique participants recruited from Amazon Mechanical Turk using the same qualification\n",
      "criteria as in Study 1. Ten tasks had to be rejected due to clearly no attempt being made to answer the task\n",
      "with relevant information. The ten tasks were republished for other participants. After collecting the data,\n",
      "we manually reviewed the results and removed a further twelve responses from participants who obviously\n",
      "tried to game the task. The final set includes 375 prompts written by 125 unique participants (three prompts\n",
      "per participant).\n",
      "4.1.3\n",
      "Analysis\n",
      "The analysis of the prompts was conducted with mixed methods. For each prompt, we qualitatively and\n",
      "quantitatively analyzed the prompts, as follows.\n",
      "14\n",
      "Prompt modifiers\n",
      "Our analysis focused on identifying the presence of specific keywords and phrases\n",
      "frequently used within the AI art community to influence the style and quality of AI-generated images\n",
      "(Oppenlaender, 2022, 2023). We opted for manual analysis in this case. An initial screening indicated that\n",
      "a very small portion of the prompts utilized prompt modifiers, making automated methods unnecessary for\n",
      "this specific task.\n",
      "The analysis process involved the first author of this paper who systematically reviewed each prompt,\n",
      "with focus on identifying specific language patterns and stylistic phrases known to impact the AI’s generative\n",
      "capabilities. This included looking for explicit instructions or adjectives that might alter the style or quality\n",
      "of the generated images. Given the clear and specific nature of these prompt modifiers, the coding focused\n",
      "on the presence or absence of these elements in each prompt. We determined that the coding process was\n",
      "straightforward – i.e., it did not require complex categorization or subjective interpretation – and, thus, did\n",
      "not necessitate validation via inter-rater agreement (McDonald, Schoenebeck, & Forte, 2019).\n",
      "We analyzed whether the prompts contained certain keywords and phrases commonly used in the AI\n",
      "art community to modify the style and quality of AI generated images (Oppenlaender, 2022, 2023). We\n",
      "decided on manual analysis because a preliminary screening revealed that very few prompts contained prompt\n",
      "modifiers. Each prompt was analyzed by an author of this paper. We coded the presence of prompt modifiers\n",
      "and report on their nature and use. We did not calculate inter-rater agreement because the coding was\n",
      "straight-forward (McDonald et al., 2019).\n",
      "Descriptive language\n",
      "A prompt written in descriptive language is likely to generate images of high\n",
      "quality. We quantitatively assessed whether the prompts contained descriptive language by calculating a\n",
      "number of statistical indices for each prompt:\n",
      "• The number of words (tokens) and unique words (types) in the prompt. In general, longer prompts\n",
      "are more likely to include certain keywords (whether on purpose or by accident) that may trigger the\n",
      "image generation system to generate images with high quality or in a certain style.\n",
      "• The Type-Token Ratio (TTR) (Johnson, 1944), a standard measure for lexical diversity defined as the\n",
      "number of types divided by the number of tokens in the prompt.3 A token, in this case, is a discrete\n",
      "word whereas a type is a unique token in the prompt. For calculating the TTR, we used Kristopher\n",
      "Kyle’s lexical-diversity Python package (Kyle, 2018).\n",
      "3We also experimented with other indices of lexical diversity, such as the Moving-Average Type-Token Ratio (MATTR)\n",
      "(Covington & McFall, 2010) and the Measure of Textual Lexical Diversity (MTLD) (McCarthy & Jarvis, 2010). However, these\n",
      "measures highly depend on the text length (Tweedie & Baayen, 1998). Only a small fraction of the prompts in our sample\n",
      "meet the recommended minimum number of tokens for applying lexical diversity measures (Zenker & Kyle, 2021). The use of\n",
      "lexical diversity indices, such as the TTR, for comparing texts of different size is not recommended (Tweedie & Baayen, 1998).\n",
      "In our study, we do not use the TTR for comparing the lexical diversity of prompts, but to assess the amount of repetition of\n",
      "tokens in the prompt.\n",
      "15\n",
      "4.2\n",
      "Results\n",
      "4.2.1\n",
      "Participants\n",
      "The 125 participants in our sample included 55 men, 67 women, 1 non-binary, and two participants who\n",
      "did not to disclose their gender identity. The age of participants ranged from 19 to 71 years (M = 41.08\n",
      "years, SD = 13.44 years). The majority of participants (98.40%) reported English being their first language.\n",
      "Thirty-seven participants (30.33%) responded positively to the question that they had “experience with text-\n",
      "based image generation systems.” We had no explanation for this surprisingly high number at this point, but\n",
      "inquired more about the participants’ background in our follow-up study in Section 5. Median completion\n",
      "times were higher than estimated in the pilot study, reaching 197 seconds. It is possible that completion\n",
      "times are skewed due to participants reserving tasks in bulk.\n",
      "4.2.2\n",
      "On the use of descriptive language\n",
      "The prompts were of varying length, ranging from 1 to 134 tokens with an average of 12.54 tokens per\n",
      "prompt (SD = 14.65 tokens). Overall, the length of prompts was appropriate for text-to-image generation\n",
      "with only four participants producing overly long prompts. On average, participants used 3.27 nouns to\n",
      "describe the subjects in their prompt (SD = 3.36). Participants used verbs only sparingly in their prompts\n",
      "(M = 0.36, SD = 1.02). The average number of prepositions (M = 1.78, SD = 2.27) was higher than the\n",
      "average number of adjectives (M = 1.65, SD = 1.95). However, this number is skewed by four participants\n",
      "who provided long prompts. These participants were very specific in what their images should contain,\n",
      "with many prepositions being used to denote the relative positions of subjects in the artwork (Max = 21\n",
      "prepositions per prompt).\n",
      "Overall, participants used rich descriptive language. The participants were creative and often described\n",
      "beautiful natural scenery.\n",
      "The main topics in the participants’ prompts were landscapes, sunsets, and\n",
      "animals.\n",
      "We note that the richness of the language in the prompts primarily is a result of the use of\n",
      "adjectives. On average, participants used 1.65 adjectives in their prompt (SD = 1.95). Colors, in particular,\n",
      "were popular among participants to describe the subjects in their artworks. The following prompts exemplify\n",
      "the creativity and the use of descriptive language among participants:\n",
      "• beautiful landscape with majestic mountains and a bright blue lake\n",
      "• bright yellow sun against a blue sky with puffy clouds\n",
      "• A fruit bowl with vibrant colored fruits in it and a contrasting background\n",
      "• Dragon on the tower of a castle in a storm.\n",
      "• Knight holding a sword that shines in the sunlight\n",
      "• A white fluffy puppy is playing in the grass with a large blue ball that is twice his size.\n",
      "16\n",
      "• A shiny black horse with eyes like coal run in a lush green grassy field\n",
      "• There should be a beautiful green forest, full of leaves, with dark brown earth beneath, and a girl in a\n",
      "dress sitting on the ground holding a book.\n",
      "More than half of the prompts (58.13%) did not repeat any tokens (that is, they had a TTR of 1;\n",
      "M = 0.94, SD = 0.10). Most of the repetitions in prompts stem from the participants’ need to identify\n",
      "the relative positions of subjects in the image (e.g., “[...] Touching the black line and going all the way\n",
      "across the top of the black line should be a dark green line. Above the dark green line should be a medium\n",
      "green line. [...]”). Repetitions, as a stylistic element in prompts (Oppenlaender, 2023), were not being used.\n",
      "Only 27 prompts (7.2% of all prompts) contained cardinal numbers (M = 0.07, SD = 0.29). Two cardinal\n",
      "numbers referred to a period in time which could potentially trigger the image generation system to produce\n",
      "images in a certain style.\n",
      "Even though we tried to mitigate it in the task design and the instructions, we noticed 18 participants\n",
      "(14.4%) still provided direct instructions to the AI instead of prompts describing the image content. These\n",
      "participants either wrote three separate instructions to the AI (e.g., “Generate a white 250 ml tea glass [...],”\n",
      "“Draw three separate triangles [...],” and “Show me some digital artwork from a brand new artist.”) or they\n",
      "wrote three consecutive instructions as we had observed in our pilot study. The latter may not include nouns\n",
      "as subject terms and could thus result in images with an undetermined subject (e.g., “sharpen image”). Two\n",
      "participants thought they could chat with the AI, asking it, for instance, “Which do you prefer: starry night\n",
      "sky or blue sea at dawn?,” “Enter your favorite geometric shape,” and “Can you paint me a rendition of the\n",
      "Monalisa?”.\n",
      "4.2.3\n",
      "On the use of prompt modifiers\n",
      "Even though participants were specifically instructed to create a digital artwork, we found only very few\n",
      "participants included style information in their prompts. Many participants described a scene in rich de-\n",
      "scriptive language, but neither mentioned artistic styles, artist names, genres, art media, nor specific artistic\n",
      "techniques. The participants’ prompts may have described an artwork, but without style information, the\n",
      "style of the generated image is left to chance and the resulting images may not match the participants’ intent\n",
      "and expectations.\n",
      "Overall, the prompts did not follow the prompt template mentioned in Section 2.2.2 and best practices\n",
      "common in the AI art community were not followed. Only one participant made purposeful use of a prompt\n",
      "modifier commonly used in the AI art community. This prompt modifier is “unreal engine.”4 The participant\n",
      "used this modifier in all her three prompts by concatenating it to the prompt with a plus sign, e.g.“rainbow\n",
      "tyrannosaurus rex + unreal engine.”\n",
      "A small minority of participants used generic keywords that could\n",
      "trigger a specific style in text-to-image generation systems. For instance, the generic term “artwork” was\n",
      "4The long-form of this modifier is “rendered in UnrealEngine,” a computer graphics game engine. Images generated with\n",
      "this prompt modifier may exhibit increased quality due to photo-realistic rendering.\n",
      "17\n",
      "used in 16 prompts (4.3%). The following list of examples reflects almost the entire set of prompts containing\n",
      "explicit style information among the 375 prompts written by participants (with style modifiers underlined):\n",
      "• Cubism portrait of a Labrador Retriever using reds and oranges\n",
      "• Paint a portrait of an old man in a park.\n",
      "• Draw a sketch of an airplane.\n",
      "• Abstract trippy colorful background\n",
      "• surreal sky castle\n",
      "• Can you paint me a rendition of the Monalisa?\n",
      "• Bob Ross, Claude Monet, Vincent Van Gogh\n",
      "• Are you able to produce any of rodans work.\n",
      "• what can you do, can you make pointillism artwork?\n",
      "Besides this sparse — and sometimes accidental — addition of style information, we find that overall,\n",
      "participants did not control the style of their creations.\n",
      "Instead of prompt modifiers, the participants’\n",
      "artwork styles were mainly determined by the participants’ use of descriptive language.\n",
      "5\n",
      "Study 3: Improving Prompts\n",
      "In a follow-up study, we investigated whether participants could improve their artworks. This study aimed\n",
      "to answer the question of whether prompt engineering is an innate skill that we humans apply intuitively or\n",
      "whether it is an acquired skill that requires expertise and practice (e.g., via learning to write prompts from\n",
      "repeated interactions with the text-to-image generation system) and knowledge of certain keywords and key\n",
      "phrases (prompt modifiers), as discussed in Section 2.2.2 and Section 4.2.3. We hypothesize that if prompt\n",
      "engineering is a learned skill, participants will not be able to significantly improve their artworks after only\n",
      "one iteration.\n",
      "5.1\n",
      "Method\n",
      "5.1.1\n",
      "Study design\n",
      "We invited the same participants who participated in Study 2 to review images generated from their own\n",
      "prompts. Participants were then asked to improve their three prompts. To this end, we designed a task\n",
      "that introduced the participant to the study’s purpose, using the same instructions as in the previous study.\n",
      "18\n",
      "We additionally highlighted that if the images presented to the participant did not look like artworks, the\n",
      "prompt should be adjusted. Like in the previous study, we avoided to mention that prompt modifiers could\n",
      "be used to achieve this aim.\n",
      "Participants were given five images for each of the three prompts they wrote in Study 2. We used the\n",
      "workerId variable on MTurk to load the participant’s previous prompts and images. Participants were then\n",
      "asked to rewrite and improve their three prompts. The task included two input fields, one pre-filled with\n",
      "their previous prompt and one for optional negative terms. In practice, negative terms are an important\n",
      "part of the toolbox of prompt engineers, primarily used for controlling the subject and quality of the image\n",
      "generation (Oppenlaender, 2023). For example, defining “watermark” and “shutterstock” as negative terms\n",
      "can reduce the occurrence of text and watermarks in the resulting image. Given the task of improving their\n",
      "previously generated artworks, we introduced negative terms as a possible tool for making improvements in\n",
      "Study 3. We studied this by incorporating it into our study design. Participants were introduced to the\n",
      "potentially surprising effects of negative terms with the help of an example. The example explained that\n",
      "adding “zebra” as a negative term to a prompt for a pedestrian crossing could potentially result in an image\n",
      "of a plain road (due to stripes being removed).\n",
      "For each prompt, we also collected information on whether the images matched the participant’s original\n",
      "expectations (given the previous prompt) and whether the participant thought the prompt needed improve-\n",
      "ment (both on a Likert-scale from 1 – Strongly Disagree to 5 – Strongly Agree). The latter was added to\n",
      "identify cases in which participants thought that no further improvement of the prompt was necessary. We\n",
      "also asked participants to rate their confidence that the new prompt would result in a better artwork (on a\n",
      "Likert scale from 1 – Not At All Confident to 5 – Highly Confident). The task concluded with demographic\n",
      "questions, including the participant’s experience with text-based image generation and interest in viewing\n",
      "and practicing art. The task design was tested and improved in a small-scale pilot study (N = 8; US$1 per\n",
      "task). The payment was set to US$1.75, aiming for an hourly pay of above minimum wage in the United\n",
      "States.\n",
      "5.1.2\n",
      "Research materials\n",
      "In this section, we describe how we selected an image generation system and how we generated images from\n",
      "the participants’ prompts.\n",
      "System selection\n",
      "We experimented with different text-to-image generation systems, including CLIP\n",
      "Guided Diffusion (512x512, Secondary Model)5, CLIP Guided Diffusion (HQ 512x512 Uncond)6, DALLE-E\n",
      "mini7, Disco Diffusion 5.3 and 5.48, Latent Diffusion9, and Majesty Diffusion 1.310. In the end, we selected\n",
      "5https://colab.research.google.com/drive/1mpkrhOjoyzPeSWy2r7T8EYRaU7amYOOi\n",
      "6https://colab.research.google.com/drive/1QBsaDAZv8np29FPbvjffbE1eytoJcsgA\n",
      "7https://github.com/borisdayma/dalle-mini\n",
      "8https://github.com/alembics/disco-diffusion\n",
      "9https://github.com/CompVis/latent-diffusion\n",
      "10https://github.com/multimodalart/majesty-diffusion\n",
      "19\n",
      "Latent Diffusion for two main reasons. Latent Diffusion is the foundation for many of the community-driven\n",
      "adaptations and modifications. More importantly, the system is deterministic and leads to reproducible\n",
      "outcomes. Consecutive runs with the same seed value will generate the same images. This is a crucial\n",
      "requirement since we aim to compare images in between studies.\n",
      "Image generation\n",
      "We generated images for the participants’ prompts with Latent Diffusion using the\n",
      "following configuration settings: text2img-large model (1.4B parameters), seed value 1040790415, eta 1.0,\n",
      "ddim steps 100, and scale 5.0. Even though the system is capable of generating images at higher resolutions,\n",
      "we decided to generate images of 256 × 256 pixels to avoid the quirks that often occur when generating\n",
      "images in resolutions that the model was not trained on. The image generation job yielded 1875 images (125\n",
      "participants × 3 prompts per participant × 5 images per prompt). After collecting the revised prompts from\n",
      "participants, we generated another set of 1875 images using the same seed value and configuration settings\n",
      "as before. Negative terms were used in this second set, if provided by the participant.\n",
      "Some hand-selected images generated from the prompts are depicted in Figure 4. Many images were of\n",
      "photo-realistic quality, depicting landscapes, sunsets, beaches, and animals. Besides photographs, artistic\n",
      "styles included paintings, graphic designs, abstract artworks, as well as magazine and book covers. Some\n",
      "images contained text and many images contained watermarks.\n",
      "5.1.3\n",
      "Analysis\n",
      "We analyzed the two sets of prompts and images written in studies 2 and 3 as follows.\n",
      "Analysis of prompts\n",
      "To measure the amount of changes in the prompts, we calculated the number of\n",
      "tokens added and removed using parts-of-speech tagging as well as the Levenshtein distance (Levenshtein,\n",
      "1965), a measure of lexical similarity denoting the minimum number of edits needed to change one string\n",
      "into another. The Levenshtein distance provides a simple measure for us to describe how much a prompt\n",
      "has changed in between the two studies. This is important to know, because it also reflects the participant’s\n",
      "satisfaction with the generated output. Clearly, there will be satisficers and maximizers among participants\n",
      "(Schwartz et al., 2002). Some participants spend more time on prompt writing than others. We argue it is\n",
      "important to have a notion of the change in between prompts, measured by the Levenshtein distance. To un-\n",
      "derstand the nature of the changes, the first author inductively developed a coding scheme (Hsieh & Shannon,\n",
      "2005) with eight categories: adjectives/adverbs, subjects, prepositions, paraphrasing/synonyms, reordering,\n",
      "cardinal numbers, simplification, and presence of prompt modifiers. After discussing the codes among all\n",
      "authors and revising the codes, the first author coded all prompts and generated a co-occurrence matrix of\n",
      "changes made by participants. Note that we understand “subjects” in the sense of subject terms (Oppen-\n",
      "laender, 2023) for image generation (e.g. “a woman holding a phone” would have two subjects (woman and\n",
      "phone). Synonyms were analyzed at the level of individual words and parts of sentences.\n",
      "20\n",
      "(a)\n",
      "(b)\n",
      "Figure 4: Selected exemplars of a) successful and b) failed image generations from worker-provided prompts.\n",
      "The images in Figure 4a were selected to represent a variety of different styles and are not representative of\n",
      "the whole set of images. The images in Figure 4b depict some of the recurring issues in images generated\n",
      "from worker-provided prompts.\n",
      "Analysis of the revised images\n",
      "We evaluated the images according to the following process, developed\n",
      "collaboratively by the authors. Initially, a spreadsheet was created with the two sets of prompts and their\n",
      "respective five images from Studies 2 and 3.\n",
      "Through a detailed discussion of 30 image-text pairs, the\n",
      "authors developed a set of evaluation criteria grounded in both the study’s objectives and relevant literature.\n",
      "Similar criteria have been used in image evaluation studies, such as (Dai et al., 2023).\n",
      "This approach\n",
      "ensured a balance between the specificity of the study and established methodologies in image evaluation.\n",
      "The criteria were designed to encompass both objective and subjective aspects of the images, including\n",
      "binary categories for failed image generations, the extent of style and subject change, and improvements in\n",
      "consistency. Additionally, we included ratings for details, contrast, color, distortions, watermarks, and an\n",
      "overall subjective impression of quality. We acknowledge that while some elements of the evaluation were\n",
      "inherently subjective, they were rooted in discussions among the authors to ensure they were relevant and\n",
      "appropriate for the context of this study. We aimed to create a comprehensive evaluation framework that\n",
      "21\n",
      "not only aligns with existing standards but also caters to the unique aspects of AI-generated imagery.\n",
      "Using the evaluation criteria, each author then individually rated 50 pairs of images along these criteria.\n",
      "After this initial round of coding, the authors discussed the results and decided to add four more criteria\n",
      "to the coding scheme. The final set of criteria included binary categories for failed generations, amount of\n",
      "style and subject change, and whether consistency improved, as well as ratings for details, contrast, color,\n",
      "distortions, watermarks, and overall subjective impression of quality. After a second round of coding, the\n",
      "authors cross-checked their evaluations and resolved differences through discussion.\n",
      "5.2\n",
      "Results\n",
      "5.2.1\n",
      "Participants\n",
      "The sample consisted of 50 participants (40% of the participants who participated in Study 2). Participants\n",
      "included 25 men, 24 women, and 1 person who preferred not to disclose the gender identity, aged 20 to\n",
      "71 years (M = 42.76, SD = 14.63). Participants came from varied educational backgrounds, including\n",
      "some completed college courses (17 participants), Bachelor’s degrees (22 participants), Master’s degrees (4\n",
      "participants), and doctorate degrees (2 participants).\n",
      "Seven out of ten participants had an educational\n",
      "30%\n",
      "22%\n",
      "46%\n",
      "80%\n",
      "56%\n",
      "48%\n",
      "20%\n",
      "12%\n",
      "14%\n",
      "30%\n",
      "34%\n",
      "8%\n",
      "I am especially interested in AI−generated\n",
      "images.§\n",
      "How often do you practice art yourself?...\n",
      "I have visited many art galleries and museums.§\n",
      "Please rate your level of experience with\n",
      "text−based image generation....\n",
      "100%\n",
      "50%\n",
      "0%\n",
      "50%\n",
      "100%\n",
      "Likert score\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "§ From 1 – Strongly Disagree to 5 – Strongly Agree\n",
      "‡ 1 – Never, 2 – Rarely, 3 – Sometimes, 4 – Often, 5 – Very often\n",
      "† 1 – Not at all experienced, 2 – Slightly experienced, 3 – Moderately experienced, 4 – Very experienced, 5 – Extremely\n",
      "experienced\n",
      "Figure 5: Background of the crowd workers participating in Study 3.\n",
      "background in the arts. Some participants were interested in visiting museums and AI-generated imagery,\n",
      "but most did not practice art themselves and 80% had little or no experience with text-to-image generation.\n",
      "Approximately 40% of participants were disappointed with the generated images, while 55% of partic-\n",
      "ipants’ expectations were met. Around 60% of participants believed the images needed improvement, and\n",
      "a similar percentage of participants were confident that their revised prompts would improve the generated\n",
      "images.\n",
      "5.2.2\n",
      "Participants’ revised prompts\n",
      "The average Levenshtein distance between the participants’ two prompts (not including negative terms)\n",
      "was 28.1 (SD = 25.0). A computational analysis of the changes with parts-of-speech tagging shows that\n",
      "22\n",
      "participants added over twice as many tokens as they removed — 538 added tokens versus 243 removed tokens\n",
      "(see Figure 7a). Nouns were added most often (29.55% of added tokens), followed by adjectives (22.12%),\n",
      "prepositions (17.84%) and determiners (8.55%). The same types of tokens were also most often removed\n",
      "(28.81% of removed tokens were nouns, 16.87% prepositions, 13.17% adjectives, and 8.64% determiners). In\n",
      "11 prompts (7.33%), the participant neither changed the prompt nor provided a negative term. Six of these\n",
      "instances consisted of participants pasting random snippets of text.\n",
      "Table 3: Evaluation of changes in the two sets of images generated from prompts in Study 3.\n",
      "details\n",
      "contrast\n",
      "color\n",
      "distortions\n",
      "watermarks\n",
      "consistency\n",
      "overall\n",
      "worse\n",
      "17 (11.3%)\n",
      "17 (11.3%)\n",
      "12 (8.0%)\n",
      "32 (21.3%)\n",
      "31 (20.7%)\n",
      "23 (15.3%)\n",
      "23 (15.3%)\n",
      "same\n",
      "81 (54.0%)\n",
      "85 (56.7%)\n",
      "88 (58.7%)\n",
      "99 (66.0%)\n",
      "85 (56.7%)\n",
      "95 (63.3%)\n",
      "77 (51.3%)\n",
      "better\n",
      "52 (34.7%)\n",
      "48 (32.0%)\n",
      "50 (33.3%)\n",
      "19 (12.7%)\n",
      "34 (22.7%)\n",
      "32 (21.3%)\n",
      "50 (33.3%)\n",
      "bright full moon just ris-\n",
      "ing over the desert\n",
      "bright full amber col-\n",
      "ored moon just rising\n",
      "over the desert\n",
      "(a)\n",
      "A famers market in Ne-\n",
      "braska in the early fall.\n",
      "An\n",
      "outdoor\n",
      "famers\n",
      "market in Nebraska in\n",
      "the early fall.\n",
      "(b)\n",
      "A forest with scary trees\n",
      "all around\n",
      "A forest with vibrant\n",
      "green trees all around.\n",
      "(c)\n",
      "A\n",
      "comfortable\n",
      "warm\n",
      "blanket\n",
      "resting\n",
      "on\n",
      "an\n",
      "antique rocking chair.\n",
      "A\n",
      "comfortable\n",
      "warm\n",
      "blanket\n",
      "resting\n",
      "on\n",
      "an\n",
      "antique rocking chair in\n",
      "front of a fireplace.\n",
      "(d)\n",
      "Are you able to produce\n",
      "any of rodans work.\n",
      "Will you please cor-\n",
      "rect\n",
      "Rodans\n",
      "artwork\n",
      "for me.\n",
      "(e)\n",
      "miracle of creation\n",
      "explosion of creativ-\n",
      "ity\n",
      "(f)\n",
      "A\n",
      "fruit\n",
      "bowl\n",
      "with\n",
      "vibrant\n",
      "colored\n",
      "fruits\n",
      "in\n",
      "it\n",
      "and\n",
      "a\n",
      "contrasting background\n",
      "A\n",
      "neutral\n",
      "colored\n",
      "bowl\n",
      "with a variety of several\n",
      "brightly\n",
      "colored\n",
      "and\n",
      "vi-\n",
      "brant\n",
      "fruits\n",
      "in\n",
      "it,\n",
      "and\n",
      "a\n",
      "background that is darker\n",
      "to contrast with the fruit.\n",
      "(g)\n",
      "A man in a blue busi-\n",
      "ness suit sitting on a\n",
      "bench. He holds a brief-\n",
      "case.\n",
      "A man seated\n",
      "on\n",
      "a\n",
      "park bench.\n",
      "He is in\n",
      "a blue business suit. A\n",
      "briefcase is beside him\n",
      "on the bench.\n",
      "(h)\n",
      "A wild cat sitting on a\n",
      "brightly-painted fence.\n",
      "A\n",
      "tiger\n",
      "stands\n",
      "on\n",
      "top\n",
      "of\n",
      "a\n",
      "fence\n",
      "that\n",
      "has been painted with\n",
      "vivid primary colors.\n",
      "(i)\n",
      "Figure 6: Examples of changes (highlighted in bold) in adjectives and adverbs (a–c), subjects (d–f) and\n",
      "multiple changes at once (g–i) made by crowd workers to their own prompts in Study 4.\n",
      "Our coding showed that the main strategy used by participants was modifying (i.e., adding, removing,\n",
      "or switching) adjectives in their prompts (see Figure 7b). For example, a participant changed the prompt\n",
      "23\n",
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "added tokens\n",
      "count\n",
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "removed tokens\n",
      "count\n",
      "(a) Histogram of changes in tokens\n",
      "63\n",
      "16 46\n",
      "11\n",
      "5\n",
      "25\n",
      "10\n",
      "1\n",
      "5\n",
      "18\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "7\n",
      "6\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "12\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n",
      "Completely different\n",
      "Prompt modifiers\n",
      "Simplify\n",
      "Reorder\n",
      "Cardinals\n",
      "Prepositions\n",
      "Paraphrase/synonyms\n",
      "Subjects\n",
      "Adjectives/adverbs\n",
      "Adjectives/Adverbs\n",
      "Subjects\n",
      "Paraphrase/synonyms\n",
      "Prepositions\n",
      "Cardinals\n",
      "Reorder\n",
      "Simplify\n",
      "Prompt modifiers\n",
      "Completely different\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "value\n",
      "(b) Co-occurrence matrix of changes\n",
      "Figure 7: Participants added more tokens than they removed in Study 3 (Figure 7a). Figure 7b depicts\n",
      "the changes that often co-occurred with one another. For instance, a change (addition or removal) to an\n",
      "adjective often co-occurred with changes to other adjectives in the prompt.\n",
      "“flowers in winter” to “purple flowers in winter.” This was often combined with changes to the subject of the\n",
      "prompt (cf. Figure 6), such as changing “sweeping arcs” to “deep and broad, sweeping arcs in landscapes.”\n",
      "Some participants also adapted their prompts based on what they saw in the images, though this often\n",
      "resulted in only minor changes to the revised images. For instance, in the case of the above participant,\n",
      "the two images of mountainous landscapes were almost identical. Another common approach was changing\n",
      "prepositions in the prompts. Few participants attempted to simplify their prompts, and relatively few made\n",
      "changes to cardinal numbers. For instance, one participant changed “draw a bunch of circles” to “draw at\n",
      "least 15 circles,” and another participant wanted to see “lots of puffy clouds” without specifying the exact\n",
      "number.\n",
      "We found that only one participant (the same as in Section 4.2.3) demonstrated knowledge of prompt\n",
      "modifiers in all three of her prompts. An example written by this participants is “rainbow tyrannosaurus rex,\n",
      ":::::::::\n",
      "prehistoric:::::::::\n",
      "landscape,\n",
      ":::::\n",
      "studio:::::\n",
      "ghibli,\n",
      ":::::::\n",
      "trending:::\n",
      "on:::::::::\n",
      "artstation.” This participant used the underlined prompt\n",
      "modifiers which are commonly used in the AI art community.\n",
      "Only one other participant used a style\n",
      "modifier (“real photos of [...]”) in one prompt. This shows a very small increase in the use of prompt\n",
      "modifiers among participants in between Study 2 and Study 3, even though participants were specifically\n",
      "instructed to improve their artworks.\n",
      "5.2.3\n",
      "Participants’ revised images\n",
      "We compared the two sets of images generated from each participant’s prompts and found that over half of\n",
      "the revised sets showed no improvement in image quality (in terms of details, contrast, color, distortions,\n",
      "watermarks, and consistency). Selected changes in the prompts and the resulting images are depicted in\n",
      "Figure 6. About half of the sets remained the same, 15% were worse, and a third were better compared to\n",
      "24\n",
      "the previous set.\n",
      "Some participants were able to make improvements to the generated images, mainly by adding more\n",
      "details. Since participants added more tokens than they removed, the prompts were longer and resulted\n",
      "in about a third of the images having more details. Some participants also improved the images’ colors\n",
      "and contrast by adding adjectives to the prompts. For instance, one participant improved the amount of\n",
      "details by adding “coral reef” to the end of the prompt “scuba diver exploring unknown ocean.” This change\n",
      "resulted in less blur and more details in the coral reef. However, strong changes in the style of the images\n",
      "were rare, with about 70% of the revised sets being in the same or very similar style. Because participants\n",
      "did not use style modifiers, the revised images often resembled the initial images.\n",
      "About 15% of the images were of low aesthetic quality, often consisting of text with no discernible subject\n",
      "(see Figure 4b). These images were rarely improved between the studies, and when they were, it was often\n",
      "due to chance. For instance, the subject was completely changed in about 10% of the images. This was\n",
      "often a result of participants trying to have a conversation with the AI and entering a completely different\n",
      "prompt as input (see Figure 6b and Figure 6e).\n",
      "5.2.4\n",
      "Participants’ use of negative terms\n",
      "Nineteen participants used negative terms, with eight using them in all three prompts. In total, we collected\n",
      "39 negative terms. Many negative terms (n = 19) aimed at removing or modifying the subject in various ways,\n",
      "such as removing “rocks” from a beach, trying to correct a “weird face,” avoiding a “Nude, Naked, White,\n",
      "Man,” removing the color “Green.” in the image of a red star, or attempting to change the subject entirely\n",
      "(“ballroom”). Participants tried to change the style of the images in eight cases, using terms such as “Black,\n",
      "White, Colorless, Monochromatic,” “opaque, solid,” and “unfocused.” Four out of the 50 participants tried\n",
      "to remove text in the images, using negative terms such as “letters,” “captions,” and “text.”\n",
      "Only one\n",
      "participant attempted to remove watermarks, using the negative term “remove watermark.”\n",
      "As can be\n",
      "seen in this prompt, some participants did not understand the concept of negative terms, even though we\n",
      "explained it to them. A few examples of failed and successful attempts are depicted in Figure 8. Some of the\n",
      "image generations failed, because the participant did not use the negative term correctly. For instance, the\n",
      "prompt on the bottom right of Figure 8 contains a monarch butterfly both in the prompt and negative term.\n",
      "The resulting image is sub-par compared to the image generated from the participant’s original prompt.\n",
      "6\n",
      "Discussion\n",
      "In three studies, we explored the skill of prompt engineering with 227 participants recruited from a crowd-\n",
      "sourcing platform. Our first study shed light on whether laypeople have an understanding of what makes\n",
      "a “good” prompt. Our findings indicate that participants can assess the quality of prompts and respec-\n",
      "tive images. This ability increased with the participants’ experience and interest in art. In the subsequent\n",
      "25\n",
      "before\n",
      "after\n",
      "revised prompt\n",
      "before\n",
      "after\n",
      "revised prompt\n",
      "An explosively bright, dying\n",
      "star.\n",
      "[Green]\n",
      "Hummingbird over red flower\n",
      "with a out of focus back-\n",
      "ground of green shrubs\n",
      "[Hummingbird hovering over\n",
      "red flower with short focal\n",
      "point.]\n",
      "medium sized metallic sphere\n",
      "slightly above and left of the\n",
      "center of the image\n",
      "[remove watermark]\n",
      "Rainbow\n",
      "colored\n",
      "unicorn\n",
      "with huge mane jumpin over\n",
      "the full moon\n",
      "[Shimmering\n",
      "hairy\n",
      "unicorn\n",
      "jumping over the full moon]\n",
      "An autumn day in a colorful\n",
      "forest\n",
      "[Dark Circle]\n",
      "Butterfly\n",
      "Monarch\n",
      "on\n",
      "a\n",
      "flower\n",
      "[Monarch butterfly alit on a\n",
      "wildflower]\n",
      "Figure 8: Examples of successful (left) and failed (right) attempts of participants using negative terms (in\n",
      "square brackets).\n",
      "two studies on writing and improving prompts, we found that participants wrote creative prompts in rich\n",
      "descriptive language which may result in beautiful digital artworks. However, only a negligible amount of\n",
      "participants applied their knowledge of art in practice and failed to use terms commonly applied in commu-\n",
      "nities of text-to-image art, such as Midjourney and Stable Diffusion. With the exception of one participant,\n",
      "these specific keywords were not (yet) part of the vocabulary of crowdsourced participants on MTurk at\n",
      "the time of our study. While the prompts written by participants were very descriptive and, in some cases,\n",
      "resulted in beautiful and interesting images, participants left the style of their image to chance. The prompts\n",
      "were missing modifiers that would more tightly control the style and quality of the image generation. This\n",
      "applies to both the initial study on writing prompts and the study on revising and improving prompts. In\n",
      "the latter, only a minority of the participants were able to improve their revised images, while most of the\n",
      "images remained about the same quality. An overwhelming majority of participants left the style of the\n",
      "generated images to chance, even though they were specifically instructed to create “artworks.”\n",
      "Reflecting on these findings, it becomes evident that while crowd engagement with AI-driven art gen-\n",
      "eration shows promise, there is a noticeable gap in the effective use of prompt engineering. This leads us\n",
      "to consider the broader implications and questions within the AI and Human-AI Interaction research fields.\n",
      "Particularly, it raises the question of whether prompt engineering is an intuitive skill that can be easily\n",
      "acquired or if it requires more specialized training and understanding.\n",
      "6.1\n",
      "Prompt Engineering as a Non-Intuitive Skill\n",
      "Our work adds to the discussion of broader research questions in the AI and Human-AI Interaction research\n",
      "communities: Can anyone become an artist with prompt engineering? Is prompt engineering a skill that\n",
      "is innate to us humans or is it a skill that needs to be acquired through practice and learning? If prompt\n",
      "26\n",
      "engineering is an intuitive skill, how intuitive is it? Or in other words, how steep is the learning curve\n",
      "to prompt engineering?\n",
      "These research questions have implications for the future of work and human-\n",
      "computer co-creativity (Kantosalo et al., 2020). If prompt engineering is an intuitive human skill that we\n",
      "humans can apply effortlessly, then we can look forward to a bright future where anyone can work in creative\n",
      "professions without having to develop special creative skills. But if prompt engineering is a non-intuitive\n",
      "skill, its application could become limited to highly trained and skilled class of creative professionals who\n",
      "have mastered to speak the language of the generative model through extensive training. The latter case\n",
      "could clearly negatively impact creative production and stifle innovation.\n",
      "Prompting is a language-based practice and the use of language is intuitive to us humans. Therefore,\n",
      "one could assume that prompting is an intuitive skill. It is easy to get started with writing prompts and\n",
      "prompting has a large potential in different fields and for many application domains. However, our study\n",
      "found that effective prompt writing requires knowledge of keywords and key phrases. These prompt modifiers\n",
      "are an essential part of the skill of prompt engineering for AI generated art. Typically, these keywords and\n",
      "key phrases are acquired through iterative experimentation and by learning from prompts shared in dedicated\n",
      "resources, on social media, or in online communities (Oppenlaender, 2022). Our studies empirically confirm\n",
      "that style modifiers are unknown to participants recruited on Amazon Mechanical Turk. Prompt modifiers\n",
      "that are being used profusely in the AI art community have not found their way into the collective vocabulary\n",
      "of crowdsourced participants on MTurk. Participants in our study struggled to write and improve their\n",
      "prompts for the specific task of creating digital artworks. This points towards prompt engineering being a\n",
      "non-intuitive skill or perhaps even a specialist skill.\n",
      "However, we acknowledge this is a simplistic view. One repeated interaction with the generative model\n",
      "does not lead to learning effects and a skill requires learning to be mastered. Perhaps a different question to\n",
      "ask is whether prompt engineering is a skill at all. The initial outputs of text-to-image generation systems\n",
      "have a high randomness and, due to the ineffectiveness of discrete language for describing images in detail,\n",
      "it is very difficult to control the initial image. Therefore, text-to-image generation often requires several\n",
      "iterations to get to an acceptable level. However, in practice, this first image is just the starting point.\n",
      "There is much more to prompt engineering than just writing textual prompts. In particular, the first image\n",
      "is generally only the start in a longer creative process that can include, for instance, ControlNet, image\n",
      "editors, image-to-image generation, inpainting and outpainting, facial detailing, and upscaling. Upscaling\n",
      "in itself is often completed with generative models, such as Real-ESRGAN (Wang, Xie, Dong, & Shan,\n",
      "2021), thereby introducing artifacts that may not be wanted, requiring further editing. Prompt engineering\n",
      "is not just tied to the use of a platform, but to a whole ecosystem of creative tools (e.g., image editors and\n",
      "generative models). Learning this variety of tools requires specific training. We speculate on four possible\n",
      "futures for the skill of prompt engineering in the following section.\n",
      "27\n",
      "6.2\n",
      "On the Future of Creative Production with Prompt Engineering\n",
      "Text-to-image generation opens new opportunities for creative production of digital images and artworks.\n",
      "Whether prompt engineering will become an expert skill or even a novel profession is still open. In this\n",
      "section, we speculate on four possible futures of prompt engineering.\n",
      "6.2.1\n",
      "Prompt engineering as an expert skill\n",
      "In the future, prompt engineering could become an expert skill that requires deep subject-matter expertise\n",
      "(e.g., knowledge of subject-specific keywords, prompt modifiers, and their combinations, but also of the\n",
      "idiosyncrasies of the training data and system configuration parameters) to effectively control the output of\n",
      "generative systems. This is similar to the move in the field of machine learning towards “foundation models”\n",
      "(Bommasani et al., 2021). Foundation models are very large and costly to train, operate, and maintain.\n",
      "As a result, the creation of these models as well as research on these models is limited to a small number\n",
      "of well-financed research institutes that employ highly-skilled professionals working in well-funded research\n",
      "institutes and organizations.\n",
      "If prompt engineering becomes a highly skilled profession, it may become\n",
      "exclusive to a narrow group of privileged individuals who have undergone extensive training.\n",
      "In our study (conducted in mid-2022), only one participant demonstrated knowledge of prompt modifiers.\n",
      "Controlling text-to-image generation is still a difficult task, and practitioners spend many hours obsessing\n",
      "over very small details. In fact, as described in the previous section, the workflow of text-to-image generation\n",
      "typically involves more steps than just prompt writing – this can be considered only the first steps in a\n",
      "complex task work flow that involves image generation models as well as editors and specialized tools. From\n",
      "this perspective, text-to-image generation remains an expert skill that, while now accessible to a large part\n",
      "of the population, remains difficult to master. This perspective is supported by the finding that most images\n",
      "generated in this study failed to achieve the given goal of creating an “artwork” (without defining what an\n",
      "artwork is and, granted, acknowledging that photographs are also art). However, prompt modifiers that\n",
      "would nudge the text-to-image generation system to produce artworks, whether photography or oil painting,\n",
      "were notably absent in the prompts written by the participants in our study.\n",
      "6.2.2\n",
      "Prompt engineering as an everyday skill\n",
      "In the future, prompt engineering could become a common practice. In this scenario, people would adapt\n",
      "their creative practices and language to facilitate effective interaction with AI because it is a skill that\n",
      "is needed in everyday life. People have a need for visual content, and AI-generated content could satisfy\n",
      "this need, from internet memes to the design of greeting cards, logos, and artworks. Prompt engineering\n",
      "could also be used for self-actualization, creativity, and therapy to improve mental health and well-being\n",
      "(Burleson, 2005). In this scenario, people would expand their existing vocabulary to include terms used in\n",
      "prompt engineering in order to produce meaningful outcomes with generative systems. Learning prompt\n",
      "engineering would be similar to learning a new language. This skill would be acquired at an early age, just\n",
      "28\n",
      "like internet literacy is today acquired effortlessly by the generation born after the internet found widespread\n",
      "use. The skill could also become part of media literacy education in schools to elevate the common skill-level\n",
      "to a professional level.\n",
      "There is some support in our studies for this speculative future. Most participants were able to write\n",
      "creative and detailed prompt. Digital literacy in using text-to-image generation systems can therefore be\n",
      "assumed to be present to some degree.\n",
      "With text-to-image technology improving, the skill of prompt\n",
      "engineering may become easier and not require as many special keywords and modifiers in the prompts.\n",
      "On the other hand, if this skill was to be used daily, participants would likely want to improve their skill to\n",
      "make use of prompt engineering more efficiently. Our study itself is an example of how rapidly the world\n",
      "changed after the wide-spread release of generative AI. It is likely that our study would have a different\n",
      "outcome today, simply because more people, today, know how to write basic prompts and perform basic\n",
      "prompt engineering. This would support the perspective of prompt engineering becoming a basic everyday\n",
      "skill.\n",
      "6.2.3\n",
      "Prompt engineering as an obsolete skill\n",
      "In the future, prompt engineering could become irrelevant. How users interact with AI models is closely\n",
      "coupled with the advances of AI technology and what the AI models are capable of. Prompt engineering\n",
      "can be seen as the smell of a half-baked product that does not solve its users’ needs. As generative systems\n",
      "improve their ability to understand the intent of users, prompt engineering could be a short-lived trend.\n",
      "The problem of aligning AI with human intent is known as AI alignment in the scholarly literature (Gabriel,\n",
      "2020). State-of-the-art systems, such as ChatGPT (OpenAI, 2022) and DALL-E 3 (Betker et al., 2023),\n",
      "demonstrate impressive performance in understanding textual input prompts and aligning with user intent.\n",
      "With these systems, users of all skill levels can generate content from textual prompts. As generative systems\n",
      "become better at understanding user intent, prompt engineering could become obsolete, similar to how we\n",
      "no longer use block printing. Prompt engineering could become unnecessary — an archaic skill that does\n",
      "not require expert training and that only few people exercise for nostalgic reasons.\n",
      "Support for this speculative future comes primarily from the creators of generative tools themselves. One\n",
      "example is Midjourney which introduced a noticeable jump in quality between version 5 and 6, with the latter\n",
      "version requiring fewer keyword modifiers in prompts (Midjourney, 2023). The CEO of Midjourney, David\n",
      "Holz, has recommended not to put too much effort into acquiring the skill of prompt engineering because\n",
      "generative systems change too quickly (Acar, 2023; Holz, 2023). Another example of the skill potentially\n",
      "becoming obsolete are language models that generate prompts. This approach is used in some text-to-image\n",
      "generation systems to rewrite the user input and improve the prompt quality. One instance of such LM-\n",
      "based prompt rewriting is used on the image generator ideogram.ai. Such prompt rewriting could, if language\n",
      "models were well aligned with user intent, make the skill of prompt engineering obsolete.\n",
      "29\n",
      "6.2.4\n",
      "Prompt engineering as personal signature or curation skill\n",
      "In the future, our human senses could become better at distinguishing hand-crafted art from AI-generated\n",
      "digital art. AI artist Mario Klingemann speculated that with the influx of AI-generated images, this skill\n",
      "would help us notice subtle nuances, details, and imperfections in AI-generated art, which could become more\n",
      "important in determining the aesthetic quality of an art piece.11 In this scenario, anyone could write prompts\n",
      "for generative systems with good results, but only a few would become masters of prompt engineering. The\n",
      "practice of prompt engineering would remain a necessary skill for applying finishing touches and optimizing\n",
      "generative results, as well as imbuing an artwork with a personal style to distinguish it from bland “off-the-\n",
      "shelf” generations. Alternatively or in parallel, prompt engineering could evolve into a curation skill — a\n",
      "personal practice in which everyone has their own curated sets of textual and visual inputs used to fine-\n",
      "tune generative models for different purposes. In this scenario, the machine would personalize and adapt to\n",
      "humans, rather than the other way around. As a result, the generative machine would potentially develop\n",
      "a perfect understanding of user intent. Current approaches that cater towards this future are Low-Rank\n",
      "Adaptation (LoRA) (Hu et al., 2022), Dreambooth (Ruiz et al., 2023) and textual inversion (Gal et al.,\n",
      "2022).\n",
      "There is some support for this possible future in our study. Participants were able to tell bad quality\n",
      "prompts from good quality prompts. This could enable participants to curate prompts. Furthermore, the\n",
      "prompts from some of our study participants had a clear personal signature.\n",
      "The idiosyncratic way of\n",
      "writing prompts was easily recognizable in some participants. Future generative models could pick up on\n",
      "these subtleties and adapt to the idiosyncrasies of their user-written prompts. This would, clearly, enable\n",
      "these models to outperform models that cannot adapt to the subtleties of user intent.\n",
      "6.2.5\n",
      "Review and outlook\n",
      "These four speculative futures were initially formulated in 2022. Two years on, there has still not been a\n",
      "definitive answer to the question which potential future is more likely and in which direction we are heading.\n",
      "School curricula have still not adapted prompt engineering. Prompt engineering is a perishable skill with\n",
      "a short shelf life. Every time a model is updated, practitioners have to adopt new tricks and the skill of\n",
      "prompt engineering has to be learned anew. Even the CEOs of generative AI companies, such as Midjourney,\n",
      "recommend not putting too much effort into learning the skill of prompt engineering, because it is changing\n",
      "too rapidly (Holz, 2023; Midjourney, 2023). On the other hand, what is enduring is the continued public\n",
      "interest in prompt engineering and its usefulness for solving real-world problems, such as question–answering\n",
      "over text documents (Lewis et al., 2020; Oppenlaender & H¨am¨al¨ainen, 2023). LM-based agents have become\n",
      "popular in industry due to their usefulness in solving difficult problems, surpassing even web development\n",
      "frameworks in popularity (Oppenlaender, 2024; Wu et al., 2024). From this perspective, prompt engineering\n",
      "– and, more generally, AI engineering – is considered a valuable skill to have and teach in school curricula\n",
      "11https://twitter.com/quasimondo/status/1512769106717593610\n",
      "30\n",
      "(Microsoft, 2024). There are now job positions made available with title ‘Prompt Engineer,’ not only at\n",
      "technology companies, but also in the public sector, such as the position of a ‘Senior Prompt Engineer’ role\n",
      "at the AI Safety Institute of the UK’s Department for Science, Innovation & Technology (Department for\n",
      "Science, Innovation & Technology, 2024). However, digging deeper into this particular job role, it is clear\n",
      "that the role of Prompt Engineer is more encompassing than just writing prompts – it requires technology\n",
      "skills, such as Python programming, and knowledge of deep learning and evaluation frameworks. Advanced\n",
      "prompting techniques are just one aspect in this job profile.\n",
      "The rapidly evolving landscape of generative AI is the crux of the skill of prompt engineering. While\n",
      "the skill is useful for hobbyists and practitioners in industry, it is changing too rapidly to make it a sensible\n",
      "addition to school curricula. As a consequence, we can expect the gap between academia and practice to\n",
      "become even wider in the coming years. With this context in mind, we now turn our attention to future work.\n",
      "6.3\n",
      "Future Work\n",
      "We conducted an experiment asking crowdsourced participants to write, improve, and assess prompts. The\n",
      "study was conducted in May–July 2022, at a time when text-to-image generation was still unknown to\n",
      "most people. Today, many people have tried text-to-image generation at least once, and many more have\n",
      "heard of the scandals and lawsuits surrounding generative AI. Knowledge of these scandals may shape the\n",
      "perception and use of generative AI (Zhu et al., 2024). Our study was conducted in mid-2022, and, today, it\n",
      "would be difficult to recruit a participant sample as naive to text-to-image generation as our sample. This\n",
      "makes our study important and valuable. This is precisely the value of our work: we evaluated prompt\n",
      "engineering as a skill with naive participants, at a time when text-to-image generation was not as popular as\n",
      "it is today. Midjourney was just released and still unknown to many people. Stable Diffusion was released\n",
      "months later, in August 2022. And ChatGPT was made available only later the same year. Our participant\n",
      "sample consisted of laypeople who were still naive to “prompt engineering” for text-to-image generation.\n",
      "Such a participant sample is hard to find today – most people have heard and tried image generators or\n",
      "language models at least once, and ChatGPT is available for free. The interaction with image generators is\n",
      "typically interactive: a user enters a prompt, observes the results, and types another prompt in response to\n",
      "the observed output. Therefore, text-to-image generation has learning built in. It is, today, very difficult to\n",
      "disentangle this aspect of interactive learning from any investigation concerned with understanding the skill\n",
      "underlying prompt engineering. In our study, participants had no experience in text-to-image generation\n",
      "(except for one participant) and underwent one repeated interaction with the system. This allowed us to\n",
      "investigate the skill of prompt engineering in our experiment. Future work should build on this, for the\n",
      "reasons outlined in Section 6.2.5, even though recruiting naive participants is challenging. Is is pertinent to\n",
      "investigate whether prompt engineering is to be included in school and high education curricula. To make\n",
      "an informed decision, one would need to know more about how quickly the skill of prompt engineering is\n",
      "learned, what it exactly entails (besides prompt writing), the steepness of the learning curve, and how long\n",
      "31\n",
      "it would take to master this skill. All these factors are needed to make an informed decision of whether\n",
      "prompt engineering is a skill to include in curricula.\n",
      "We investigated textual prompt engineering in our paper. But there are more facets to text-to-image gen-\n",
      "eration in practice, as discussed in Section 6.1 and outlined in Oppenlaender (2022), such as visual prompting\n",
      "and configuration parameters in text-to-image generation systems. Future research should consider the com-\n",
      "plexity and diversity of skills and should always consider all facets involved in the creative process, not just\n",
      "textual prompts. Future work could envision how the machine can adapt to humans and possibly provide\n",
      "guidelines for AI researchers, so they can develop AI models that understand user intent and foster a more\n",
      "“intimate” relationship with users (Weiser, 1993). Language – whether written or spoken – is the perfect\n",
      "vehicle for this intimate relationship with users.\n",
      "6.4\n",
      "Limitations\n",
      "We acknowledge a number of risks to the validity of our exploratory studies. Aesthetic quality assessment,\n",
      "as explored in Study 1, inherently carries a high degree of subjectivity (Joshi et al., 2011). Various factors\n",
      "influence such ratings, including personal values, background, image content and its interestingness, contrast,\n",
      "proportion, number of elements, novelty, and appropriateness (Joshi et al., 2011; Khalighy, Green, Scheepers,\n",
      "& Whittet, 2014; Kong et al., 2016). We acknowledge that the task given to participants in Study 1 was\n",
      "challenging, particularly in terms of visualizing and evaluating the potential outcome of a written prompt.\n",
      "While our findings indicate that participants could discern between low and high-quality prompts, we must\n",
      "also recognize a key limitation: the absence of direct measurements for the actual quality of the generated\n",
      "artworks themselves. This gap points to the difficulty in quantitatively assessing artistic creations, a challenge\n",
      "further compounded by the subjective nature of aesthetic evaluation. Future research could benefit from\n",
      "developing more concrete and objective criteria or methods to assess the quality of prompt–artwork pairs,\n",
      "providing a more comprehensive understanding of the relationship between prompt quality and the resulting\n",
      "art.\n",
      "We further acknowledge limitations in our choice of text-to-image generation system. Our main motiva-\n",
      "tion for selecting Latent Diffusion was, at the time, that it was a state-of-the-art image generation system\n",
      "allowing the deterministic and reproducible generation of images. We tested a dozen of other text-to-image\n",
      "generation systems, notably CLIP-Guided Diffusion, GLID-3-XL, DALL-E mini (Craiyon), Latent Majesty\n",
      "Diffusion, DISCO Diffusion, and VQGAN-CLIP (Crowson et al., 2022), with mixed results. Some systems\n",
      "had non-deterministic (random) components leading to image generations not being reproducible. Other\n",
      "systems were not advanced enough, at the time, to produce recognizable results. Note, however, that while\n",
      "Latent Diffusion is a powerful image generation system, it may respond differently to style keywords than\n",
      "CLIP-guided systems. Our choice of latent diffusion was a compromise between reproducibility and perfor-\n",
      "mance. In any case, we argue the choice of image generation system does not matter much for our study. Our\n",
      "study setup did not provide interactive feedback to participants, and the system itself was not our subject\n",
      "32\n",
      "of study. Instead, we were interested in the intrinsic skill of participants. However, only one participant\n",
      "used specific keywords (prompt modifiers) in our study. The second round of images was also never shown\n",
      "to participants. Therefore, we can safely assert that the choice of system had no effect on how participants\n",
      "adapted to the generative system and how they wrote and revised their prompts.\n",
      "Regarding the observation about participants making greater improvements in prompts but not in mod-\n",
      "ifiers in Study 3, we realize that our initial instructions did not explicitly guide participants to modify the\n",
      "stylistic elements or modifiers of the prompts. This oversight might have led to less emphasis on altering these\n",
      "aspects, thus skewing the results in favor of more noticeable changes in the prompts’ substantive content.\n",
      "However, the overall tasks given to the participant was to improve the artwork, and the instructions were\n",
      "thus implicitly part of the given task. As an alternative approach, a more directed instruction could have\n",
      "provided insights into how novice users interact with and perceive the importance of prompt modifiers in\n",
      "text-to-image generation. This realization could be a valuable consideration for the design of future studies.\n",
      "Last, we acknowledge that to explore the dynamics of prompting skill learning, a long-term field study\n",
      "would need to be conducted. However, our one time modification experiment provides a first indication\n",
      "indicating that the skill of prompting is not an innate skill that users can apply without learning about it\n",
      "first. Recent work by Don-Yehiya, Choshen, and Abend (2023) provides intriguing insights on the dynamics\n",
      "of prompt learning on Midjourney that future work could build on.\n",
      "7\n",
      "Conclusion\n",
      "The past few years have seen the rise of generative models. It is too early to tell whether this development\n",
      "will give birth to new professions, such as “prompt engineer.” However, generative AI will deeply affect and\n",
      "reconfigure the fabric of our society. This opens exciting opportunities for research in the field of HCI.\n",
      "This article investigated prompt engineering, as a new type of skill, in the context of AI art. In three\n",
      "studies, we investigated whether laypeople naive to text-to-image generation could recognize the quality of\n",
      "prompts and their resulting images, and whether participants could write and improve prompts, without\n",
      "repeated feedback from the image generation system. We found participants recruited from a crowdsourcing\n",
      "platform were creative and able to write prompts for text-to-image generation systems in rich descriptive\n",
      "language, but lacked the special vocabulary found in AI art communities. The use of prompt modifiers was\n",
      "not intuitive to participants, pointing towards prompt engineering being a non-intuitive skill. We discussed\n",
      "the importance of our study’s findings, and speculated on four possible futures for prompt engineering. We\n",
      "hope that whatever the landscape of creative production will turn out to be in the future, it will be an\n",
      "inclusive creative economy in which everyone can participate in meaningful ways.\n",
      "33\n",
      "References\n",
      "Acar, O. A. (2023). AI prompt engineering isn’t the future. Harvard Business Review. Retrieved from\n",
      "https://hbr.org/2023/06/ai-prompt-engineering-isnt-the-future\n",
      "Allen, C. (2022). Zippy’s disco diffusion cheatsheet v0.3. (https://docs.google.com/document/d/1l8s7uS2d\n",
      "GqjztYSjPpzlmXLjl5PM3IGkRWI3IiCuK7g/edit)\n",
      "Arai, S., & Kawabata, H.\n",
      "(2016).\n",
      "Appreciation contexts modulate aesthetic evaluation and perceived\n",
      "duration of pictures. Art & Perception, 4(3), 225 - 239. doi: 10.1163/22134913-00002052\n",
      "Bach, S., Sanh, V., Yong, Z. X., Webson, A., Raffel, C., Nayak, N. V., . . . Rush, A. (2022, 5). PromptSource:\n",
      "An integrated development environment and repository for natural language prompts. In Proceedings\n",
      "of the 60th annual meeting of the association for computational linguistics: System demonstrations\n",
      "(pp. 93–104). Dublin, Ireland: Association for Computational Linguistics. Retrieved from https://\n",
      "aclanthology.org/2022.acl-demo.9 doi: 10.18653/v1/2022.acl-demo.9\n",
      "Bateman, S., Teevan, J., & White, R. W. (2012). The search dashboard: How reflection and comparison\n",
      "impact search behavior. In Proceedings of the sigchi conference on human factors in computing systems\n",
      "(p. 1785–1794). New York, NY, USA: Association for Computing Machinery. doi: 10.1145/2207676\n",
      ".2208311\n",
      "Betker, J., Goh, G., Jing, L., Brooks, T., Wang, J., Li, L., . . . Ramesh, A.\n",
      "(2023).\n",
      "Improving image\n",
      "generation with better captions. Retrieved from https://cdn.openai.com/papers/dall-e-3.pdf\n",
      "Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., . . . Liang, P. (2021). On the\n",
      "opportunities and risks of foundation models. Retrieved from https://crfm.stanford.edu/assets/\n",
      "report.pdf\n",
      "Burleson, W. (2005). Developing creativity, motivation, and self-actualization with learning systems. Inter-\n",
      "national Journal of Human-Computer Studies, 63(4), 436-451. doi: 10.1016/j.ijhcs.2005.04.007\n",
      "Covington, M. A., & McFall, J. D. (2010). Cutting the gordian knot: The moving-average type–token ratio\n",
      "(mattr). Journal of Quantitative Linguistics, 17(2), 94-100. doi: 10.1080/09296171003643098\n",
      "Crowson, K., Biderman, S., Kornis, D., Stander, D., Hallahan, E., Castricato, L., & Raff, E. (2022). VQGAN-\n",
      "CLIP: Open domain image generation and editing with natural language guidance.\n",
      "In S. Avidan,\n",
      "G. Brostow, M. Ciss´e, G. M. Farinella, & T. Hassner (Eds.), Computer vision – eccv 2022 (pp. 88–\n",
      "105). Cham: Springer Nature Switzerland.\n",
      "Dai, X., Hou, J., Ma, C.-Y., Tsai, S., Wang, J., Wang, R., . . . Parikh, D. (2023). Emu: Enhancing image\n",
      "generation models using photogenic needles in a haystack.\n",
      "Dang, H., Goller, S., Lehmann, F., & Buschek, D. (2023). Choice over control: How users write with large\n",
      "language models using diegetic and non-diegetic prompting. In Proceedings of the 2023 chi conference\n",
      "on human factors in computing systems. New York, NY, USA: Association for Computing Machinery.\n",
      "doi: 10.1145/3544548.3580969\n",
      "Dang, H., Mecke, L., Lehmann, F., Goller, S., & Buschek, D. (2022). How to prompt? Opportunities and\n",
      "34\n",
      "challenges of zero- and few-shot learning for human-AI interaction in creative applications of generative\n",
      "models. In Generative AI and HCI workshop at CHI 2022. doi: 10.48550/ARXIV.2209.01390\n",
      "Deckers, N., Fr¨obe, M., Kiesel, J., Pandolfo, G., Schr¨oder, C., Stein, B., & Potthast, M. (2023). The infinite\n",
      "index: Information retrieval on generative text-to-image models. In Proceedings of the 2023 conference\n",
      "on human information interaction and retrieval (p. 172–186). New York, NY, USA: Association for\n",
      "Computing Machinery. doi: 10.1145/3576840.3578327\n",
      "Department for Science, Innovation & Technology. (2024). Senior prompt engineer – autonomous systems\n",
      "(ai safety institute). Retrieved from https://archive.today/bhV6I\n",
      "Dhariwal, P., & Nichol, A. Q. (2021). Diffusion models beat GANs on image synthesis. In A. Beygelzimer,\n",
      "Y. Dauphin, P. Liang, & J. W. Vaughan (Eds.), Advances in neural information processing systems.\n",
      "Retrieved from https://openreview.net/forum?id=AAWuCvzaVt\n",
      "Don-Yehiya, S., Choshen, L., & Abend, O. (2023). Human learning by model feedback: The dynamics of\n",
      "iterative prompting with midjourney.\n",
      "Gabha, H. (2022). Disco diffusion 70+ artist studies. Retrieved from https://weirdwonderfulai.art/\n",
      "resources/disco-diffusion-70-plus-artist-studies/\n",
      "Gabriel, I. (2020). Artificial intelligence, values, and alignment. Minds and Machines, 30(3), 411-437. doi:\n",
      "10.1007/s11023-020-09539-2\n",
      "Gal, R., Alaluf, Y., Atzmon, Y., Patashnik, O., Bermano, A. H., Chechik, G., & Cohen-Or, D. (2022). An\n",
      "image is worth one word: Personalizing text-to-image generation using textual inversion. arXiv. doi:\n",
      "10.48550/ARXIV.2208.01618\n",
      "Gerger, G., Leder, H., & Kremer, A. (2014). Context effects on emotional and aesthetic evaluations of\n",
      "artworks and IAPS pictures. Acta Psychologica, 151, 174-183. doi: 10.1016/j.actpsy.2014.06.008\n",
      "Grassini, S., & Koivisto, M. (2024). Artificial creativity? Evaluating AI against human performance in\n",
      "creative interpretation of visual stimuli. International Journal of Human–Computer Interaction, 0(0),\n",
      "1–12. doi: 10.1080/10447318.2024.2345430\n",
      "Haddington, P., Hirvonen, N., Hosio, S., Kinnula, M., Malmberg, J., Seyfi, S., . . . Zabolotna, K. (2021). GenZ\n",
      "white paper: Strengthening human competences in the emerging digital era (Tech. Rep.). University of\n",
      "Oulu. Retrieved from http://jultika.oulu.fi/files/isbn9789526231471.pdf\n",
      "Hayward, J. (2022, 9 17). The growing art movement of ‘promptism’. Retrieved from https://medium.com/\n",
      "counterarts/the-growing-art-movement-of-promptism-9ec956d82a61\n",
      "Hoare, M., Benford, S., Jones, R., & Milic-Frayling, N. (2014). Coming in from the margins: Amateur\n",
      "musicians in the online age. In Proceedings of the sigchi conference on human factors in computing\n",
      "systems (p. 1295–1304). New York, NY: Association for Computing Machinery. doi: 10.1145/2556288\n",
      ".2557298\n",
      "Holz, D. (2023). Midjourney office hours. Personal communication via Discord.\n",
      "H. Onan Demirel, X. L., Molly H. Goldstein, & Sha, Z. (2024). Human-centered generative design framework:\n",
      "35\n",
      "An early design framework to support concept creation and evaluation.\n",
      "International Journal of\n",
      "Human–Computer Interaction, 40(4), 933–944. doi: 10.1080/10447318.2023.2171489\n",
      "Hope, T., Tamari, R., Hershcovich, D., Kang, H. B., Chan, J., Kittur, A., & Shahaf, D. (2022). Scaling\n",
      "creative inspiration with fine-grained functional aspects of ideas. In Chi conference on human factors\n",
      "in computing systems. New York, NY: Association for Computing Machinery. doi: 10.1145/3491102\n",
      ".3517434\n",
      "Hou, Y., Dong, H., Wang, X., Li, B., & Che, W. (2022, 10). MetaPrompting: Learning to learn better\n",
      "prompts. In Proceedings of the 29th international conference on computational linguistics (pp. 3251–\n",
      "3262). International Committee on Computational Linguistics. Retrieved from https://aclanthology\n",
      ".org/2022.coling-1.287\n",
      "Hsieh, H.-F., & Shannon, S. E. (2005). Three approaches to qualitative content analysis. Qualitative health\n",
      "research, 15(9), 1277–1288.\n",
      "Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., . . . Chen, W. (2022). LoRA: Low-rank\n",
      "adaptation of large language models. In International conference on learning representations. Retrieved\n",
      "from https://openreview.net/forum?id=nZeVKeeFYf9\n",
      "Huang, J., & Efthimiadis, E. N.\n",
      "(2009).\n",
      "Analyzing and evaluating query reformulation strategies in\n",
      "web search logs.\n",
      "In Proceedings of the 18th acm conference on information and knowledge man-\n",
      "agement (p. 77–86).\n",
      "New York, NY, USA: Association for Computing Machinery.\n",
      "doi: 10.1145/\n",
      "1645953.1645966\n",
      "Jeong Soo Kim, M. K., & Baek, T. H. (2024). Enhancing user experience with a generative AI chatbot. Inter-\n",
      "national Journal of Human–Computer Interaction, 0(0), 1–13. doi: 10.1080/10447318.2024.2311971\n",
      "Jiang, E., Olson, K., Toh, E., Molina, A., Donsbach, A., Terry, M., & Cai, C. J. (2022). Promptmaker:\n",
      "Prompt-based prototyping with large language models. In Extended abstracts of the 2022 chi conference\n",
      "on human factors in computing systems. New York, NY, USA: Association for Computing Machinery.\n",
      "doi: 10.1145/3491101.3503564\n",
      "Johnson, W. (1944). Studies in language behavior 1: A program of research. Psychological Monographs, 56,\n",
      "1–15.\n",
      "Joshi, D., Datta, R., Fedorovskaya, E., Luong, Q.-T., Wang, J. Z., Li, J., & Luo, J. (2011). Aesthetics and\n",
      "emotions in images. IEEE Signal Processing Magazine, 28(5), 94-115. doi: 10.1109/MSP.2011.941851\n",
      "Kantosalo, A., Thattai Ravikumar, P., Grace, K., & Takala, T. (2020, 9 7). Modalities, styles and strategies:\n",
      "An interaction framework for human–computer co-creativity. In A. Cardoso, P. Machado, T. Veale, &\n",
      "J. Cunha (Eds.), Proceedings of the eleventh international conference on computational creativity (pp.\n",
      "57–64). Association for Computational Creativity.\n",
      "Khalighy, S., Green, G., Scheepers, C., & Whittet, C. (2014). Measuring aesthetic in design. In Proceedings\n",
      "of the DESIGN 2014 13th international design conference (p. 2083-2094). The Design Society.\n",
      "Kim, S., Eun, J., Oh, C., & Lee, J. (2024). “journey of finding the best query”: Understanding the user\n",
      "36\n",
      "experience of AI image generation system. International Journal of Human–Computer Interaction,\n",
      "1–19.\n",
      "Kong, S., Shen, X., Lin, Z., Mech, R., & Fowlkes, C. (2016). Photo aesthetics ranking network with attributes\n",
      "and content adaptation. In B. Leibe, J. Matas, N. Sebe, & M. Welling (Eds.), Computer vision – eccv\n",
      "2016 (pp. 662–679). Cham: Springer International Publishing.\n",
      "Kugler, L.\n",
      "(2021, 8).\n",
      "Non-fungible tokens and the future of art.\n",
      "Commun. ACM , 64(9), 19–20.\n",
      "doi:\n",
      "10.1145/3474355\n",
      "Kyle, K. (2018). lexical-diversity python package. Retrieved from https://github.com/kristopherkyle/\n",
      "lexical diversity\n",
      "Lee, S.-y., Law, M., & Hoffman, G. (2024). When and how to use AI in the design process? implications\n",
      "for human-AI design collaboration. International Journal of Human–Computer Interaction, 1–16. doi:\n",
      "10.1080/10447318.2024.2353451\n",
      "Levenshtein, V. I. (1965). Binary codes capable of correcting deletions, insertions, and reversals. Soviet\n",
      "physics. Doklady, 10, 707-710.\n",
      "Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., . . . Kiela, D. (2020). Retrieval-\n",
      "augmented generation for knowledge-intensive NLP tasks. In Proceedings of the 34th international\n",
      "conference on neural information processing systems. Red Hook, NY, USA: Curran Associates Inc.\n",
      "Liu, V., & Chilton, L. B. (2022). Design guidelines for prompt engineering text-to-image generative models.\n",
      "In Chi conference on human factors in computing systems. New York, NY: Association for Computing\n",
      "Machinery. doi: 10.1145/3491102.3501825\n",
      "McCarthy, P. M., & Jarvis, S. (2010). Mtld, vocd-d, and hd-d: A validation study of sophisticated approaches\n",
      "to lexical diversity assessment. Behavior Research Methods, 42(2), 381–392. doi: 10.3758/brm.42.2\n",
      ".381\n",
      "McDonald, N., Schoenebeck, S., & Forte, A. (2019, 11). Reliability and inter-rater reliability in qualitative\n",
      "research: Norms and guidelines for CSCW and HCI practice. Proc. ACM Hum.-Comput. Interact.,\n",
      "3(CSCW). doi: 10.1145/3359174\n",
      "Merriam-Webster. (2024). Skill. Retrieved from https://www.merriam-webster.com/dictionary/skill\n",
      "Microsoft.\n",
      "(2024,\n",
      "5\n",
      "8).\n",
      "2024\n",
      "work\n",
      "trend\n",
      "index\n",
      "annual\n",
      "report\n",
      "(Tech.\n",
      "Rep.).\n",
      "Author.\n",
      "Retrieved from https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is\n",
      "-here-now-comes-the-hard-part\n",
      "Midjourney. (2022). Midjourney.com. Retrieved from https://www.midjourney.com\n",
      "Midjourney.\n",
      "(2023,\n",
      "12 21).\n",
      "Announcement.\n",
      "Retrieved from https://discord.com/channels/\n",
      "662267976984297473/952771221915840552/1187272332268556298\n",
      "OpenAI. (2022). ChatGPT: Optimizing language models for dialogue. Retrieved from https://openai.com/\n",
      "blog/chatgpt/\n",
      "Oppenlaender, J. (2022). The creativity of text-to-image generation. In 25th international academic mindtrek\n",
      "37\n",
      "conference (p. 192–202). New York, NY, USA: Association for Computing Machinery. doi: 10.1145/\n",
      "3569219.3569352\n",
      "Oppenlaender, J.\n",
      "(2023).\n",
      "A taxonomy of prompt modifiers for text-to-image generation.\n",
      "Behaviour &\n",
      "Information Technology, 1-14. doi: 10.1080/0144929X.2023.2286532\n",
      "Oppenlaender, J. (2024). The cultivated practices of text-to-image generation.\n",
      "doi: 10.48550/arXiv.2306.11393\n",
      "Oppenlaender, J., Abbas, T., & Gadiraju, U. (2024, 4). The state of pilot study reporting in crowdsourcing:\n",
      "A reflection on best practices and guidelines. Proc. ACM Hum.-Comput. Interact., 8(CSCW1). doi:\n",
      "10.1145/3641023\n",
      "Oppenlaender, J., & H¨am¨al¨ainen, J. (2023). Mapping the challenges of HCI: An application and evaluation\n",
      "of ChatGPT and GPT-4 for mining insights at scale. doi: 10.48550/arXiv.2306.05036\n",
      "Oppenlaender, J., Silvennoinen, J., Paananen, V., & Visuri, A. (2023). Perceptions and realities of text-to-\n",
      "image generation. In Proceedings of the 26th international academic mindtrek conference (p. 279–288).\n",
      "New York, NY, USA: Association for Computing Machinery. doi: 10.1145/3616961.3616978\n",
      "Oppenlaender, J., Visuri, A., Paananen, V., Linder, R., & Silvennoinen, J. (2023). Text-to-image generation:\n",
      "Perceptions and realities. In Workshop on generative AI and HCI at CHI ’23. doi: 10.48550/arXiv\n",
      ".2303.13530\n",
      "Pelowski, M., Gerger, G., Chetouani, Y., Markey, P. S., & Leder, H. (2017). But is it really art? The\n",
      "classification of images as “art”/“not art” and correlation with appraisal and viewer interpersonal\n",
      "differences. Frontiers in Psychology, 8. doi: 10.3389/fpsyg.2017.01729\n",
      "Pinson, M. H., Janowski, L., Pepion, R., Huynh-Thu, Q., Schmidmer, C., Corriveau, P., . . . Ingram, W.\n",
      "(2012). The influence of subjects and environment on audiovisual subjective tests: An international\n",
      "study. IEEE Journal of Selected Topics in Signal Processing, 6(6), 640-651. doi: 10.1109/JSTSP.2012\n",
      ".2215306\n",
      "Qiao, H., Liu, V., & Chilton, L. (2022). Initial images: Using image prompts to improve subject repre-\n",
      "sentation in multimodal AI generated art. In Creativity and cognition (p. 15–28). New York, NY:\n",
      "Association for Computing Machinery. doi: 10.1145/3527927.3532792\n",
      "Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., . . . Sutskever, I.\n",
      "(2021, 7).\n",
      "Learning transferable visual models from natural language supervision.\n",
      "In M. Meila & T. Zhang\n",
      "(Eds.), Proceedings of the 38th international conference on machine learning (Vol. 139, pp. 8748–8763).\n",
      "PMLR.\n",
      "Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., & Chen, M. (2022). Hierarchical text-conditional image\n",
      "generation with CLIP latents. arXiv. doi: 10.48550/ARXIV.2204.06125\n",
      "Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., . . . Sutskever, I. (2021, 7). Zero-shot text-\n",
      "to-image generation. In M. Meila & T. Zhang (Eds.), Proceedings of the 38th international conference\n",
      "on machine learning (Vol. 139, pp. 8821–8831). PMLR. Retrieved from https://proceedings.mlr\n",
      "38\n",
      ".press/v139/ramesh21a.html\n",
      "Reynolds, L., & McDonell, K. (2021). Prompt programming for large language models: Beyond the few-shot\n",
      "paradigm. In Extended abstracts of the 2021 chi conference on human factors in computing systems.\n",
      "New York, NY, USA: Association for Computing Machinery. doi: 10.1145/3411763.3451760\n",
      "Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2022). High-resolution image synthesis\n",
      "with latent diffusion models. In 2022 ieee/cvf conference on computer vision and pattern recognition\n",
      "(cvpr) (p. 10674-10685). doi: 10.1109/CVPR52688.2022.01042\n",
      "Ruiz, N., Li, Y., Jampani, V., Pritch, Y., Rubinstein, M., & Aberman, K. (2023, 6). Dreambooth: Fine\n",
      "tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF\n",
      "conference on computer vision and pattern recognition (p. 22500-22510).\n",
      "Schwartz, B., Ward, A., Monterosso, J., Lyubomirsky, S., White, K., & Lehman, D. R. (2002). Maximizing\n",
      "versus satisficing: Happiness is a matter of choice. Journal of Personality and Social Psychology, 83(5),\n",
      "1178–1197. doi: 10.1037/0022-3514.83.5.1178\n",
      "Siahaan, E., Redi, J. A., & Hanjalic, A. (2014). Beauty is in the scale of the beholder: Comparison of method-\n",
      "ologies for the subjective assessment of image aesthetic appeal. In 2014 sixth international workshop\n",
      "on quality of multimedia experience (qomex) (p. 245-250). doi: 10.1109/QoMEX.2014.6982326\n",
      "Smith, E. (2022). A traveler’s guide to the latent space. Retrieved from https://sweet-hall-e72.notion\n",
      ".site/A-Traveler-s-Guide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f\n",
      "Surowiecki, J. (2005). The wisdom of crowds. Anchor.\n",
      "Tweedie, F. J., & Baayen, R. H. (1998). How variable may a constant be? Measures of lexical richness in\n",
      "perspective. Computers and the Humanities, 32(5), 323–352.\n",
      "Van Dongen, N. N., Van Strien, J. W., & Dijkstra, K. (2016). Implicit emotion regulation in the context of\n",
      "viewing artworks: ERP evidence in response to pleasant and unpleasant pictures. Brain and Cognition,\n",
      "107, 48-54. doi: 10.1016/j.bandc.2016.06.003\n",
      "Wang, X., Xie, L., Dong, C., & Shan, Y. (2021). Real-ESRGAN: Training real-world blind super-resolution\n",
      "with pure synthetic data.\n",
      "In 2021 ieee/cvf international conference on computer vision workshops\n",
      "(iccvw) (p. 1905-1914). doi: 10.1109/ICCVW54120.2021.00217\n",
      "Weiser, M. (1993, 7). Some computer science issues in ubiquitous computing. Commun. ACM , 36(7), 75–84.\n",
      "doi: 10.1145/159544.159617\n",
      "White, R. W., Dumais, S. T., & Teevan, J.\n",
      "(2009).\n",
      "Characterizing the influence of domain expertise\n",
      "on web search behavior.\n",
      "In Proceedings of the second acm international conference on web search\n",
      "and data mining (p. 132–141). New York, NY, USA: Association for Computing Machinery. doi:\n",
      "10.1145/1498759.1498819\n",
      "Wood, E., Pasquale, D. D., Mueller, J. L., Archer, K., Zivcakova, L., Walkey, K., & Willoughby, T. (2016).\n",
      "Exploration of the relative contributions of domain knowledge and search expertise for conducting\n",
      "internet searches. The Reference Librarian, 57(3), 182-204. doi: 10.1080/02763877.2015.1122559\n",
      "39\n",
      "Wu, Q., Bansal, G., Zhang, J., Wu, Y., Li, B., Zhu, E., . . . Wang, C. (2024). AutoGen: Enabling next-gen\n",
      "LLM applications via multi-agent conversation. Retrieved from https://openreview.net/forum?id=\n",
      "tEAF9LBdgu\n",
      "Xie, Y., Pan, Z., Ma, J., Jie, L., & Mei, Q. (2023). A prompt log analysis of text-to-image generation systems.\n",
      "In Proceedings of the acm web conference 2023 (p. 3892–3902). New York, NY, USA: Association for\n",
      "Computing Machinery. doi: 10.1145/3543507.3587430\n",
      "Zenker, F., & Kyle, K. (2021). Investigating minimum text lengths for lexical diversity indices. Assessing\n",
      "Writing, 47. doi: 10.1016/j.asw.2020.100505\n",
      "Zhang, L., Rao, A., & Agrawala, M. (2023). Adding conditional control to text-to-image diffusion models.\n",
      "In 2023 ieee/cvf international conference on computer vision (iccv) (p. 3813-3824).\n",
      "doi: 10.1109/\n",
      "ICCV51070.2023.00355\n",
      "Zhu, W., Huang, L., Zhou, X., Li, X., Shi, G., Ying, J., & Wang, C. (2024). Could AI ethical anxiety,\n",
      "perceived ethical risks and ethical awareness about ai influence university students’ use of generative\n",
      "AI products? an ethical perspective. International Journal of Human–Computer Interaction, 0(0),\n",
      "1–23. doi: 10.1080/10447318.2024.2323277\n",
      "Zylinska, J. (2020). AI art: Machine visions and warped dreams. London, UK: Open Humanities Press.\n",
      "40\n",
      "A\n",
      "Set of images used in Study 1\n",
      "A.1\n",
      "Images with High Aesthetic Appeal\n",
      "H1: the foundations of ori-\n",
      "gin, matte painting, genesis,\n",
      "trending on artstation, high\n",
      "resolution\n",
      "H4: eclectic interior of the\n",
      "mind\n",
      "H5: , ., ., matte painting, 8k\n",
      "cgsociety\n",
      "H6:\n",
      "The Dude by Glenn\n",
      "Fabry\n",
      "H2: vikings. by Dan Mumford, matte\n",
      "painting, Studio Ghibli\n",
      "H7:\n",
      "fantastic wardrobe of the inner\n",
      "sanctuary comes to life in giant birta-\n",
      "tion of the soul\n",
      "H9: tidal wave, matte painting, ren-\n",
      "dered in octane, ghibli, 8k #epic #wow\n",
      "trending on wikiart\n",
      "H8: a moment of silence for\n",
      "our fallen heroes. War memo-\n",
      "rial.\n",
      "central.\n",
      "CGSociety,\n",
      "painting, postprocessing\n",
      "H10: portrait of a world war\n",
      "soldier on artstation\n",
      "H3: buck, Hudson River School\n",
      "41\n",
      "A.2\n",
      "Images with Low Aesthetic Appeal\n",
      "L1:\n",
      "Multi-Fidelity\n",
      "Met-\n",
      "aLearning for Efficient and\n",
      "Robust AutoDL\n",
      "L2: a tweet about bias\n",
      "L3:\n",
      "Asterix at the Robot\n",
      "Games.\n",
      "by Rene Goscinny\n",
      "and Albert Uderzo\n",
      "L4: amazing green screen ef-\n",
      "fect\n",
      "L5: Office Space, Bill Lum-\n",
      "bergh.\n",
      "“yeah, we need you\n",
      "to\n",
      "come\n",
      "in\n",
      "on\n",
      "Saturday,\n",
      "mkay?”\n",
      "L6:\n",
      "Blind\n",
      "No.\n",
      "20,\n",
      "Seventeen-foot high Ceiling\n",
      "or Lower, Historical Verid-\n",
      "ian\n",
      "Green,\n",
      "Indian\n",
      "Yellow\n",
      "Hue, Hansa Yellow Medium\n",
      "(to Mike Kelley)\n",
      "L7:\n",
      "we can do it!\n",
      "propa-\n",
      "ganda poster\n",
      "L8: My New Band Is Called\n",
      "Syskill\n",
      "L9: China buys Russia\n",
      "L10: artwork, academic pa-\n",
      "per\n",
      "42\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T17:06:35.090669Z",
     "start_time": "2025-08-21T17:04:25.814177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "result = summarizer(article_text[:2000], min_length=20, max_length=80, do_sample=False)\n",
    "result[0]['summary_text']\n",
    "print(result)"
   ],
   "id": "a7cfea0e29abc7f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' The paper investigates prompt engineering as a novel creative skill for creating AI art with text-to-image generation . Prompt engineering is a new type of skill that is non-intuitive and must first be acquired before it can be used .'}]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T17:08:06.488099Z",
     "start_time": "2025-08-21T17:08:06.028935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% number of characters\n",
    "a = len(result[0]['summary_text'].split(' '))\n",
    "print(\"Länge: \" + str(a))"
   ],
   "id": "a7799fc31e77a1ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge: 41\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
